{
    "id": "1hid6fh",
    "title": "The opt-out conundrum: Analysis of web scraping to train AI models | Internet Freedom Foundation",
    "url": "https://www.reddit.com/r/india/comments/1hid6fh/the_optout_conundrum_analysis_of_web_scraping_to/",
    "selftext": "https://preview.redd.it/93al3jjazx7e1.png?width=1000&format=png&auto=webp&s=201cbf0cbb2ce15184fc84bc04814b9e05a850de\n\n# tl;dr\n\nSocial media companies have recently seen an exponential increase in the use of AI. The companies have been accused of scraping data from their users for training these AI models without obtaining explicit consent from their users. In our post, we discuss these concerns which are being raised in various jurisdictions and whether opting out is a choice given to us by the law. \n\n# Background \n\nBeginning last year, there have been multiple revelations regarding social media platforms using user data to train their own AI models. In most cases, users were not explicitly notified that their data was being used to train AI models. In the past few months, revelations surrounding social media platforms using user data to train their AI models have led to public outcry. \n\nIn September 2023, Meta [announced](https://about.fb.com/news/2023/09/privacy-matters-metas-generative-ai-features/?ref=static.internetfreedom.in) the launch of its new generative AI feature. The announcement states that considering generative AI takes a large amount of data to train, it used publicly shared posts from Instagram and Facebook, including photos and text, as data to train its generative AI models. In mid June 2024, Meta [informed](https://www.bbc.com/news/articles/cw99n3qjeyjo?ref=static.internetfreedom.in) its users in the European Union (“**EU**”) and the United Kingdom (“**UK**”) that it has made changes to its privacy policy allowing it to use their information to develop and improve its AI products. This led to public opposition and complaints being filed before data protection authorities across Europe. In September 2024, before an inquiry by the Australian Senate, Meta’s global privacy director [admitted](https://www.abc.net.au/news/2024-09-11/facebook-scraping-photos-data-no-opt-out/104336170?ref=static.internetfreedom.in) to scraping data of Australian adults to train its AI models from as early as 2007 without providing an opt out option. \n\nFurther, in September 2024, 404media [reported](https://www.404media.co/linkedin-is-training-ai-on-user-data-before-updating-its-terms-of-service/?ref=static.internetfreedom.in) that LinkedIn introduced a new privacy setting saying that data from the platform is being used to train AI models, without simultaneously updating its privacy policy. LinkedIn has since then updated its [privacy policy](https://www.linkedin.com/legal/privacy-policy?ref=static.internetfreedom.in#use) to state that “*We may use your personal data to improve, develop, and provide products and Services, develop and train artificial intelligence (AI) models, develop, provide, and personalize our Services, and gain insights with the help of AI, automated systems, and inferences, so that our Services can be more relevant and useful to you and others.*”. \n\nIn September 2024, the US Federal Trade Commission (FTC) published a [report](https://www.ftc.gov/system/files/ftc_gov/pdf/Social-Media-6b-Report-9-11-2024.pdf?ref=static.internetfreedom.in) on the surveillance activities of nine of the largest social media and video streaming services, namely Amazon, Facebook, YouTube, Twitter, Snap, ByteDance, Discord, Reddit, and WhatsApp. The report highlighted that these platforms conduct extensive surveillance, gathering such vast amounts of data that they are unable to fully identify all the data points they collect or all the third parties with whom they share this information. Such incidents have shown that companies around the world have been silently scraping our data and training their AI models, which makes us question what we can do to prevent them from doing so.\n\n# Navigating the Opting Out Maze\n\nThe fact remains that in India, and most other jurisdictions barring the EU, social media platforms have not asked for explicit consent before using user data to train AI models. However, there are opt out mechanisms that social media platforms offer to allow users to halt access to their data by the platform for training AI models or any other purpose. Unfortunately, the opt out options mostly only let you stop some future data grabbing, not whatever happened in the past. Further, companies behind AI chatbots often do not provide details about what ‘training’ or ‘improving’ their AI models means in relation to your interactions. As a result, it's unclear what you are actually opting out of if you choose to do so. \n\nWhile social media platforms do provide some vague opt out mechanisms for preventing companies from using your data to train their AI models, these are often not made plainly available and require the user to delve into the minute wordings of the application’s settings and permissions. \n\nLet’s try to break down some ways in which you can opt out: \n\n1. **LinkedIn**\n\nLinkedIn wrote [on its help page](https://www.linkedin.com/help/linkedin/answer/a6278444?ref=static.internetfreedom.in) that it uses generative AI for purposes like writing assistant features. We can revoke permission by heading to the Data privacy tab in your account settings and clicking on “[Data for Generative AI Improvement](https://www.linkedin.com/mypreferences/d/settings/data-for-ai-improvement?ref=static.internetfreedom.in)” to find the toggle. Turn it to “off” to opt out. \n\nThe FAQ regarding its AI training states that it employs \"privacy-enhancing technologies to redact or remove personal data\" from its training datasets and that it does not train its models on individuals residing in the EU, EEA, or Switzerland.\n\n1. **X**\n\nX, formerly known as Twitter, automatically activated a setting that allowed the company to train its Grok AI on users’ posts. X enabled the new setting by default. On X, you can click [Privacy](https://techcrunch.com/2024/07/26/heres-how-to-disable-x-twitter-from-using-your-data-to-train-its-grok-ai/?ref=static.internetfreedom.in), then Data sharing and personalization: there you'll find a permission checkbox that you can uncheck to stop X's Grok A.I. model from using your account data “for training and fine-tuning,” as well as an option to clear past personal data that may have been used before you opted out.\n\n1. **Meta**\n\nThis year, Meta [reignited](https://techcrunch.com/2024/09/13/meta-reignites-plans-to-train-ai-using-uk-users-public-facebook-and-instagram-posts/?ref=static.internetfreedom.in) its controversial plans to use the public posts of Facebook and Instagram users as AI training data. This resulted in both good and bad news. The bad news was that users in the US or other countries without national data privacy laws had no foolproof way to prevent Meta from using their data to train AI, which has likely already been done. Meta does not offer an opt-out feature for people living in these regions. The good news, however, was for users in the European Union and the UK, which are protected by strict data protection laws. They have the right to object to their data being scraped, allowing them to opt out more easily.\n\n1. **Bluesky**\n\nRecently, social networking platform Bluesky said that, unlike other social media platforms, it would not rely on user content to train generative artificial intelligence (AI) models. However, it was [pointed out](https://www.404media.co/someone-made-a-dataset-of-one-million-bluesky-posts-for-machine-learning-research/?ref=static.internetfreedom.in) by some users that Bluesky itself does not train AI models on user data, it just does not prevent others from using its data for training purposes. The company responded that just like other open websites on the internet, it is considering implementing a consent system for how other companies access Bluesky users' data. The proposed system would let Bluesky users indicate whether they consent to their content being used for AI training. \n\nIt also makes us wonder how AI chatbots are utilising our data where people are choosing to share personal information. Read more about this [here](https://www.washingtonpost.com/technology/2024/05/31/opt-out-ai-training-meta-chatgpt/?ref=static.internetfreedom.in).\n\n# Is opting out mandated by a law? Perspectives from around the globe\n\nSocial media companies do not tend to divulge much about their AI refinement and training processes, which makes it harder to make an informed choice about opting out. This raises the question: is opting out even mandated by law, or is it a choice that companies can make?\n\nThere are varying answers depending on the jurisdiction. \n\nFor those living in the United States, where online privacy laws are not as strict, companies can use public posts to train their A.I. This was noticed when Meta launched its new generative AI feature and technically were not required to notify users, and therefore users may not have realized that it had been training its A.I. with their public posts. So, if you want to opt out, you have to make your account private. Meta later also clarified that [private messages](https://www.facebook.com/privacy/genai/) between family and friends are not used to train its AI.\n\nThose using Meta apps within the European Union, Britain, the European Economic Area and Switzerland were notified that they could opt out, according to Meta. These jurisdictions are protected by strict [data protection](https://www.gtlaw-dataprivacydish.com/2023/06/what-gdpr-requirements-does-a-company-that-uses-personal-information-to-train-an-artificial-intelligence-ai-need-to-meet/?ref=static.internetfreedom.in) regimes, users have the right to object to their data being scraped, so they can opt out more easily. For instance, under the EU’s General Data Protection Regulation (“**GDPR**”), [Article 14](https://gdpr-info.eu/art-14-gdpr/?ref=static.internetfreedom.in) states that individuals ought to be informed about the collection of their personal information (including the purpose of collection), even if this data has not been obtained from the individuals, i.e., inclusion of publicly available data. These and other obligations resulted in companies in the EU informing users about web scraping for the purpose of AI model training. \n\nNow, coming to India, we have the [Digital Personal Data Protection  Act, 2023](https://www.meity.gov.in/writereaddata/files/Digital%20Personal%20Data%20Protection%20Act%202023.pdf?ref=static.internetfreedom.in) (“**DPDP Act**”), which is yet to be operationalized. However, the DPDP Act excludes publicly available personal data from its scope. This means that AI entities scraping publicly available personal data for self-training may not be required to comply with data fiduciary obligations (e.g., obtaining prior consent). The DPDP Act does not require individuals to be notified about the collection and subsequent processing of data they might make publicly availab\n\nis, generating public awareness about the potential use of public personal data for AI modelling and training, deepfake creation, and possibly commercialization without users’ knowledge is becoming critical.\n\nConsidering that India has just enacted its first data protection law (the DPDP Act), its adequacy to deal with emerging challenges such as web scrapping ought to be considered. The very fact that even if the DPDP Act were in force, companies can get away with using user data to train their AI models is evidence that this law is not equipped to deal with emerging threats to individuals’ data. Any new law, but specifically those that deal with new technologies must be future proof and equipped to handle any new threats to the rights it seeks to provide. There is a significant need for India to deeply consider whether the DPDP Act is sufficient to protect the personal data of individuals. Considering that we are still awaiting the issue of rules under the DPDP Act, the real efficacy of the law remains to be ascertained. \n\nSuch trends exhibit that public social media posts are seen as fair game and can be hoovered into AI training data sets by anyone. Social media companies are conveniently relinquishing their responsibility by asking users who do not want their data to be used to set their account settings to private to minimize the risk. This implies that in practicality opt-outing settings mostly give the users an illusion of control. To counter this, data protection regimes around the world need to facilitate and build within themselves the right to object. The users need to have a clear method of opting out which is lacking in various jurisdictions presently. \n\n[Help us watch the watchdogs, support our work now!](https://static.internetfreedom.in/donate)",
    "flair": "Policy/Economy",
    "score": 7,
    "num_comments": 1,
    "created_utc": 1734673749.0,
    "convurl": "https://external-preview.redd.it/XNGfw7xVvAcqT2jiuRXOqVJAUwSZ_vsOLROUNU_9rXA.jpg?auto=webp&s=e3f9152c91616d1cb601b898cae4a4e9e38fea6c",
    "comments": [
        "there are some many more important things for IFF to focus on in India."
    ],
    "cleaned_text": "optout conundrum analysis web scraping train ai models internet freedom foundation tldr social media companies recently seen exponential increase use ai companies accused scraping data users training ai models without obtaining explicit consent users post discuss concerns raised various jurisdictions whether opting choice given us law background beginning last year multiple revelations regarding social media platforms using user data train ai models cases users explicitly notified data used train ai models past months revelations surrounding social media platforms using user data train ai models led public outcry september meta announcedhttpsaboutfbcomnewsprivacymattersmetasgenerativeaifeaturesrefstaticinternetfreedomin launch new generative ai feature announcement states considering generative ai takes large amount data train used publicly shared posts instagram facebook including photos text data train generative ai models mid june meta informedhttpswwwbbccomnewsarticlescwnqjeyjorefstaticinternetfreedomin users european union eu united kingdom uk made changes privacy policy allowing use information develop improve ai products led public opposition complaints filed data protection authorities across europe september inquiry australian senate metas global privacy director admittedhttpswwwabcnetaunewsfacebookscrapingphotosdatanooptoutrefstaticinternetfreedomin scraping data australian adults train ai models early without providing opt option september media reportedhttpswwwmediacolinkedinistrainingaionuserdatabeforeupdatingitstermsofservicerefstaticinternetfreedomin linkedin introduced new privacy setting saying data platform used train ai models without simultaneously updating privacy policy linkedin since updated privacy policyhttpswwwlinkedincomlegalprivacypolicyrefstaticinternetfreedominuse state may use personal data improve develop provide products services develop train artificial intelligence ai models develop provide personalize services gain insights help ai automated systems inferences services relevant useful others september us federal trade commission ftc published reporthttpswwwftcgovsystemfilesftcgovpdfsocialmediabreportpdfrefstaticinternetfreedomin surveillance activities nine largest social media video streaming services namely amazon facebook youtube twitter snap bytedance discord reddit whatsapp report highlighted platforms conduct extensive surveillance gathering vast amounts data unable fully identify data points collect third parties share information incidents shown companies around world silently scraping data training ai models makes us question prevent navigating opting maze fact remains india jurisdictions barring eu social media platforms asked explicit consent using user data train ai models however opt mechanisms social media platforms offer allow users halt access data platform training ai models purpose unfortunately opt options mostly let stop future data grabbing whatever happened past companies behind ai chatbots often provide details training improving ai models means relation interactions result unclear actually opting choose social media platforms provide vague opt mechanisms preventing companies using data train ai models often made plainly available require user delve minute wordings applications settings permissions lets try break ways opt linkedin linkedin wrote help pagehttpswwwlinkedincomhelplinkedinanswerarefstaticinternetfreedomin uses generative ai purposes like writing assistant features revoke permission heading data privacy tab account settings clicking data generative ai improvementhttpswwwlinkedincommypreferencesdsettingsdataforaiimprovementrefstaticinternetfreedomin find toggle turn opt faq regarding ai training states employs privacyenhancing technologies redact remove personal data training datasets train models individuals residing eu eea switzerland x x formerly known twitter automatically activated setting allowed company train grok ai users posts x enabled new setting default x click privacyhttpstechcrunchcomhereshowtodisablextwitterfromusingyourdatatotrainitsgrokairefstaticinternetfreedomin data sharing personalization youll find permission checkbox uncheck stop xs grok ai model using account data training finetuning well option clear past personal data may used opted meta year meta reignitedhttpstechcrunchcommetareignitesplanstotrainaiusingukuserspublicfacebookandinstagrampostsrefstaticinternetfreedomin controversial plans use public posts facebook instagram users ai training data resulted good bad news bad news users us countries without national data privacy laws foolproof way prevent meta using data train ai likely already done meta offer optout feature people living regions good news however users european union uk protected strict data protection laws right object data scraped allowing opt easily bluesky recently social networking platform bluesky said unlike social media platforms would rely user content train generative artificial intelligence ai models however pointed outhttpswwwmediacosomeonemadeadatasetofonemillionblueskypostsformachinelearningresearchrefstaticinternetfreedomin users bluesky train ai models user data prevent others using data training purposes company responded like open websites internet considering implementing consent system companies access bluesky users data proposed system would let bluesky users indicate whether consent content used ai training also makes us wonder ai chatbots utilising data people choosing share personal information read herehttpswwwwashingtonpostcomtechnologyoptoutaitrainingmetachatgptrefstaticinternetfreedomin opting mandated law perspectives around globe social media companies tend divulge much ai refinement training processes makes harder make informed choice opting raises question opting even mandated law choice companies make varying answers depending jurisdiction living united states online privacy laws strict companies use public posts train ai noticed meta launched new generative ai feature technically required notify users therefore users may realized training ai public posts want opt make account private meta later also clarified private messageshttpswwwfacebookcomprivacygenai family friends used train ai using meta apps within european union britain european economic area switzerland notified could opt according meta jurisdictions protected strict data protectionhttpswwwgtlawdataprivacydishcomwhatgdprrequirementsdoesacompanythatusespersonalinformationtotrainanartificialintelligenceaineedtomeetrefstaticinternetfreedomin regimes users right object data scraped opt easily instance eus general data protection regulation gdpr article httpsgdprinfoeuartgdprrefstaticinternetfreedomin states individuals ought informed collection personal information including purpose collection even data obtained individuals ie inclusion publicly available data obligations resulted companies eu informing users web scraping purpose ai model training coming india digital personal data protection act httpswwwmeitygovinwritereaddatafilesdigitalpersonaldataprotectionactpdfrefstaticinternetfreedomin dpdp act yet operationalized however dpdp act excludes publicly available personal data scope means ai entities scraping publicly available personal data selftraining may required comply data fiduciary obligations eg obtaining prior consent dpdp act require individuals notified collection subsequent processing data might make publicly availab generating public awareness potential use public personal data ai modelling training deepfake creation possibly commercialization without users knowledge becoming critical considering india enacted first data protection law dpdp act adequacy deal emerging challenges web scrapping ought considered fact even dpdp act force companies get away using user data train ai models evidence law equipped deal emerging threats individuals data new law specifically deal new technologies must future proof equipped handle new threats rights seeks provide significant need india deeply consider whether dpdp act sufficient protect personal data individuals considering still awaiting issue rules dpdp act real efficacy law remains ascertained trends exhibit public social media posts seen fair game hoovered ai training data sets anyone social media companies conveniently relinquishing responsibility asking users want data used set account settings private minimize risk implies practicality optouting settings mostly give users illusion control counter data protection regimes around world need facilitate build within right object users need clear method opting lacking various jurisdictions presently help us watch watchdogs support work nowhttpsstaticinternetfreedomindonate ",
    "cleaned_title": "optout conundrum analysis web scraping train ai models internet freedom foundation",
    "cleaned_selftext": "tldr social media companies recently seen exponential increase use ai companies accused scraping data users training ai models without obtaining explicit consent users post discuss concerns raised various jurisdictions whether opting choice given us law background beginning last year multiple revelations regarding social media platforms using user data train ai models cases users explicitly notified data used train ai models past months revelations surrounding social media platforms using user data train ai models led public outcry september meta announcedhttpsaboutfbcomnewsprivacymattersmetasgenerativeaifeaturesrefstaticinternetfreedomin launch new generative ai feature announcement states considering generative ai takes large amount data train used publicly shared posts instagram facebook including photos text data train generative ai models mid june meta informedhttpswwwbbccomnewsarticlescwnqjeyjorefstaticinternetfreedomin users european union eu united kingdom uk made changes privacy policy allowing use information develop improve ai products led public opposition complaints filed data protection authorities across europe september inquiry australian senate metas global privacy director admittedhttpswwwabcnetaunewsfacebookscrapingphotosdatanooptoutrefstaticinternetfreedomin scraping data australian adults train ai models early without providing opt option september media reportedhttpswwwmediacolinkedinistrainingaionuserdatabeforeupdatingitstermsofservicerefstaticinternetfreedomin linkedin introduced new privacy setting saying data platform used train ai models without simultaneously updating privacy policy linkedin since updated privacy policyhttpswwwlinkedincomlegalprivacypolicyrefstaticinternetfreedominuse state may use personal data improve develop provide products services develop train artificial intelligence ai models develop provide personalize services gain insights help ai automated systems inferences services relevant useful others september us federal trade commission ftc published reporthttpswwwftcgovsystemfilesftcgovpdfsocialmediabreportpdfrefstaticinternetfreedomin surveillance activities nine largest social media video streaming services namely amazon facebook youtube twitter snap bytedance discord reddit whatsapp report highlighted platforms conduct extensive surveillance gathering vast amounts data unable fully identify data points collect third parties share information incidents shown companies around world silently scraping data training ai models makes us question prevent navigating opting maze fact remains india jurisdictions barring eu social media platforms asked explicit consent using user data train ai models however opt mechanisms social media platforms offer allow users halt access data platform training ai models purpose unfortunately opt options mostly let stop future data grabbing whatever happened past companies behind ai chatbots often provide details training improving ai models means relation interactions result unclear actually opting choose social media platforms provide vague opt mechanisms preventing companies using data train ai models often made plainly available require user delve minute wordings applications settings permissions lets try break ways opt linkedin linkedin wrote help pagehttpswwwlinkedincomhelplinkedinanswerarefstaticinternetfreedomin uses generative ai purposes like writing assistant features revoke permission heading data privacy tab account settings clicking data generative ai improvementhttpswwwlinkedincommypreferencesdsettingsdataforaiimprovementrefstaticinternetfreedomin find toggle turn opt faq regarding ai training states employs privacyenhancing technologies redact remove personal data training datasets train models individuals residing eu eea switzerland x x formerly known twitter automatically activated setting allowed company train grok ai users posts x enabled new setting default x click privacyhttpstechcrunchcomhereshowtodisablextwitterfromusingyourdatatotrainitsgrokairefstaticinternetfreedomin data sharing personalization youll find permission checkbox uncheck stop xs grok ai model using account data training finetuning well option clear past personal data may used opted meta year meta reignitedhttpstechcrunchcommetareignitesplanstotrainaiusingukuserspublicfacebookandinstagrampostsrefstaticinternetfreedomin controversial plans use public posts facebook instagram users ai training data resulted good bad news bad news users us countries without national data privacy laws foolproof way prevent meta using data train ai likely already done meta offer optout feature people living regions good news however users european union uk protected strict data protection laws right object data scraped allowing opt easily bluesky recently social networking platform bluesky said unlike social media platforms would rely user content train generative artificial intelligence ai models however pointed outhttpswwwmediacosomeonemadeadatasetofonemillionblueskypostsformachinelearningresearchrefstaticinternetfreedomin users bluesky train ai models user data prevent others using data training purposes company responded like open websites internet considering implementing consent system companies access bluesky users data proposed system would let bluesky users indicate whether consent content used ai training also makes us wonder ai chatbots utilising data people choosing share personal information read herehttpswwwwashingtonpostcomtechnologyoptoutaitrainingmetachatgptrefstaticinternetfreedomin opting mandated law perspectives around globe social media companies tend divulge much ai refinement training processes makes harder make informed choice opting raises question opting even mandated law choice companies make varying answers depending jurisdiction living united states online privacy laws strict companies use public posts train ai noticed meta launched new generative ai feature technically required notify users therefore users may realized training ai public posts want opt make account private meta later also clarified private messageshttpswwwfacebookcomprivacygenai family friends used train ai using meta apps within european union britain european economic area switzerland notified could opt according meta jurisdictions protected strict data protectionhttpswwwgtlawdataprivacydishcomwhatgdprrequirementsdoesacompanythatusespersonalinformationtotrainanartificialintelligenceaineedtomeetrefstaticinternetfreedomin regimes users right object data scraped opt easily instance eus general data protection regulation gdpr article httpsgdprinfoeuartgdprrefstaticinternetfreedomin states individuals ought informed collection personal information including purpose collection even data obtained individuals ie inclusion publicly available data obligations resulted companies eu informing users web scraping purpose ai model training coming india digital personal data protection act httpswwwmeitygovinwritereaddatafilesdigitalpersonaldataprotectionactpdfrefstaticinternetfreedomin dpdp act yet operationalized however dpdp act excludes publicly available personal data scope means ai entities scraping publicly available personal data selftraining may required comply data fiduciary obligations eg obtaining prior consent dpdp act require individuals notified collection subsequent processing data might make publicly availab generating public awareness potential use public personal data ai modelling training deepfake creation possibly commercialization without users knowledge becoming critical considering india enacted first data protection law dpdp act adequacy deal emerging challenges web scrapping ought considered fact even dpdp act force companies get away using user data train ai models evidence law equipped deal emerging threats individuals data new law specifically deal new technologies must future proof equipped handle new threats rights seeks provide significant need india deeply consider whether dpdp act sufficient protect personal data individuals considering still awaiting issue rules dpdp act real efficacy law remains ascertained trends exhibit public social media posts seen fair game hoovered ai training data sets anyone social media companies conveniently relinquishing responsibility asking users want data used set account settings private minimize risk implies practicality optouting settings mostly give users illusion control counter data protection regimes around world need facilitate build within right object users need clear method opting lacking various jurisdictions presently help us watch watchdogs support work nowhttpsstaticinternetfreedomindonate",
    "cleaned_comments": "many important things iff focus india",
    "light_cleaned_title": "The opt-out conundrum: Analysis of web scraping to train AI models | Internet Freedom Foundation",
    "light_cleaned_selftext": "# tl;dr Social media companies have recently seen an exponential increase in the use of AI. The companies have been accused of scraping data from their users for training these AI models without obtaining explicit consent from their users. In our post, we discuss these concerns which are being raised in various jurisdictions and whether opting out is a choice given to us by the law. # Background Beginning last year, there have been multiple revelations regarding social media platforms using user data to train their own AI models. In most cases, users were not explicitly notified that their data was being used to train AI models. In the past few months, revelations surrounding social media platforms using user data to train their AI models have led to public outcry. In September 2023, Meta [announced](https://about.fb.com/news/2023/09/privacy-matters-metas-generative-ai-features/?ref=static.internetfreedom.in) the launch of its new generative AI feature. The announcement states that considering generative AI takes a large amount of data to train, it used publicly shared posts from Instagram and Facebook, including photos and text, as data to train its generative AI models. In mid June 2024, Meta [informed](https://www.bbc.com/news/articles/cw99n3qjeyjo?ref=static.internetfreedom.in) its users in the European Union (“**EU**”) and the United Kingdom (“**UK**”) that it has made changes to its privacy policy allowing it to use their information to develop and improve its AI products. This led to public opposition and complaints being filed before data protection authorities across Europe. In September 2024, before an inquiry by the Australian Senate, Meta’s global privacy director [admitted](https://www.abc.net.au/news/2024-09-11/facebook-scraping-photos-data-no-opt-out/104336170?ref=static.internetfreedom.in) to scraping data of Australian adults to train its AI models from as early as 2007 without providing an opt out option. Further, in September 2024, 404media [reported](https://www.404media.co/linkedin-is-training-ai-on-user-data-before-updating-its-terms-of-service/?ref=static.internetfreedom.in) that LinkedIn introduced a new privacy setting saying that data from the platform is being used to train AI models, without simultaneously updating its privacy policy. LinkedIn has since then updated its [privacy policy](https://www.linkedin.com/legal/privacy-policy?ref=static.internetfreedom.in#use) to state that “*We may use your personal data to improve, develop, and provide products and Services, develop and train artificial intelligence (AI) models, develop, provide, and personalize our Services, and gain insights with the help of AI, automated systems, and inferences, so that our Services can be more relevant and useful to you and others.*”. In September 2024, the US Federal Trade Commission (FTC) published a [report](https://www.ftc.gov/system/files/ftc_gov/pdf/Social-Media-6b-Report-9-11-2024.pdf?ref=static.internetfreedom.in) on the surveillance activities of nine of the largest social media and video streaming services, namely Amazon, Facebook, YouTube, Twitter, Snap, ByteDance, Discord, Reddit, and WhatsApp. The report highlighted that these platforms conduct extensive surveillance, gathering such vast amounts of data that they are unable to fully identify all the data points they collect or all the third parties with whom they share this information. Such incidents have shown that companies around the world have been silently scraping our data and training their AI models, which makes us question what we can do to prevent them from doing so. # Navigating the Opting Out Maze The fact remains that in India, and most other jurisdictions barring the EU, social media platforms have not asked for explicit consent before using user data to train AI models. However, there are opt out mechanisms that social media platforms offer to allow users to halt access to their data by the platform for training AI models or any other purpose. Unfortunately, the opt out options mostly only let you stop some future data grabbing, not whatever happened in the past. Further, companies behind AI chatbots often do not provide details about what ‘training’ or ‘improving’ their AI models means in relation to your interactions. As a result, it's unclear what you are actually opting out of if you choose to do so. While social media platforms do provide some vague opt out mechanisms for preventing companies from using your data to train their AI models, these are often not made plainly available and require the user to delve into the minute wordings of the application’s settings and permissions. Let’s try to break down some ways in which you can opt out: 1. **LinkedIn** LinkedIn wrote [on its help page](https://www.linkedin.com/help/linkedin/answer/a6278444?ref=static.internetfreedom.in) that it uses generative AI for purposes like writing assistant features. We can revoke permission by heading to the Data privacy tab in your account settings and clicking on “[Data for Generative AI Improvement](https://www.linkedin.com/mypreferences/d/settings/data-for-ai-improvement?ref=static.internetfreedom.in)” to find the toggle. Turn it to “off” to opt out. The FAQ regarding its AI training states that it employs \"privacy-enhancing technologies to redact or remove personal data\" from its training datasets and that it does not train its models on individuals residing in the EU, EEA, or Switzerland. 1. **X** X, formerly known as Twitter, automatically activated a setting that allowed the company to train its Grok AI on users’ posts. X enabled the new setting by default. On X, you can click [Privacy](https://techcrunch.com/2024/07/26/heres-how-to-disable-x-twitter-from-using-your-data-to-train-its-grok-ai/?ref=static.internetfreedom.in), then Data sharing and personalization: there you'll find a permission checkbox that you can uncheck to stop X's Grok A.I. model from using your account data “for training and fine-tuning,” as well as an option to clear past personal data that may have been used before you opted out. 1. **Meta** This year, Meta [reignited](https://techcrunch.com/2024/09/13/meta-reignites-plans-to-train-ai-using-uk-users-public-facebook-and-instagram-posts/?ref=static.internetfreedom.in) its controversial plans to use the public posts of Facebook and Instagram users as AI training data. This resulted in both good and bad news. The bad news was that users in the US or other countries without national data privacy laws had no foolproof way to prevent Meta from using their data to train AI, which has likely already been done. Meta does not offer an opt-out feature for people living in these regions. The good news, however, was for users in the European Union and the UK, which are protected by strict data protection laws. They have the right to object to their data being scraped, allowing them to opt out more easily. 1. **Bluesky** Recently, social networking platform Bluesky said that, unlike other social media platforms, it would not rely on user content to train generative artificial intelligence (AI) models. However, it was [pointed out](https://www.404media.co/someone-made-a-dataset-of-one-million-bluesky-posts-for-machine-learning-research/?ref=static.internetfreedom.in) by some users that Bluesky itself does not train AI models on user data, it just does not prevent others from using its data for training purposes. The company responded that just like other open websites on the internet, it is considering implementing a consent system for how other companies access Bluesky users' data. The proposed system would let Bluesky users indicate whether they consent to their content being used for AI training. It also makes us wonder how AI chatbots are utilising our data where people are choosing to share personal information. Read more about this [here](https://www.washingtonpost.com/technology/2024/05/31/opt-out-ai-training-meta-chatgpt/?ref=static.internetfreedom.in). # Is opting out mandated by a law? Perspectives from around the globe Social media companies do not tend to divulge much about their AI refinement and training processes, which makes it harder to make an informed choice about opting out. This raises the question: is opting out even mandated by law, or is it a choice that companies can make? There are varying answers depending on the jurisdiction. For those living in the United States, where online privacy laws are not as strict, companies can use public posts to train their A.I. This was noticed when Meta launched its new generative AI feature and technically were not required to notify users, and therefore users may not have realized that it had been training its A.I. with their public posts. So, if you want to opt out, you have to make your account private. Meta later also clarified that [private messages](https://www.facebook.com/privacy/genai/) between family and friends are not used to train its AI. Those using Meta apps within the European Union, Britain, the European Economic Area and Switzerland were notified that they could opt out, according to Meta. These jurisdictions are protected by strict [data protection](https://www.gtlaw-dataprivacydish.com/2023/06/what-gdpr-requirements-does-a-company-that-uses-personal-information-to-train-an-artificial-intelligence-ai-need-to-meet/?ref=static.internetfreedom.in) regimes, users have the right to object to their data being scraped, so they can opt out more easily. For instance, under the EU’s General Data Protection Regulation (“**GDPR**”), [Article 14](https://gdpr-info.eu/art-14-gdpr/?ref=static.internetfreedom.in) states that individuals ought to be informed about the collection of their personal information (including the purpose of collection), even if this data has not been obtained from the individuals, i.e., inclusion of publicly available data. These and other obligations resulted in companies in the EU informing users about web scraping for the purpose of AI model training. Now, coming to India, we have the [Digital Personal Data Protection Act, 2023](https://www.meity.gov.in/writereaddata/files/Digital%20Personal%20Data%20Protection%20Act%202023.pdf?ref=static.internetfreedom.in) (“**DPDP Act**”), which is yet to be operationalized. However, the DPDP Act excludes publicly available personal data from its scope. This means that AI entities scraping publicly available personal data for self-training may not be required to comply with data fiduciary obligations (e.g., obtaining prior consent). The DPDP Act does not require individuals to be notified about the collection and subsequent processing of data they might make publicly availab is, generating public awareness about the potential use of public personal data for AI modelling and training, deepfake creation, and possibly commercialization without users’ knowledge is becoming critical. Considering that India has just enacted its first data protection law (the DPDP Act), its adequacy to deal with emerging challenges such as web scrapping ought to be considered. The very fact that even if the DPDP Act were in force, companies can get away with using user data to train their AI models is evidence that this law is not equipped to deal with emerging threats to individuals’ data. Any new law, but specifically those that deal with new technologies must be future proof and equipped to handle any new threats to the rights it seeks to provide. There is a significant need for India to deeply consider whether the DPDP Act is sufficient to protect the personal data of individuals. Considering that we are still awaiting the issue of rules under the DPDP Act, the real efficacy of the law remains to be ascertained. Such trends exhibit that public social media posts are seen as fair game and can be hoovered into AI training data sets by anyone. Social media companies are conveniently relinquishing their responsibility by asking users who do not want their data to be used to set their account settings to private to minimize the risk. This implies that in practicality opt-outing settings mostly give the users an illusion of control. To counter this, data protection regimes around the world need to facilitate and build within themselves the right to object. The users need to have a clear method of opting out which is lacking in various jurisdictions presently. [Help us watch the watchdogs, support our work now!](https://static.internetfreedom.in/donate)",
    "light_cleaned_comments": "there are some many more important things for IFF to focus on in India."
}