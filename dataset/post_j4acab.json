{
    "id": "j4acab",
    "title": "Read our comments on the DoT's Paper to develop an Indian AI Stack",
    "url": "https://www.reddit.com/r/india/comments/j4acab/read_our_comments_on_the_dots_paper_to_develop_an/",
    "selftext": "&amp;#x200B;\n\nhttps://preview.redd.it/owp0jtt5etq51.png?width=1600&amp;format=png&amp;auto=webp&amp;s=59d8d953871c3d33d5e787fafb5d0692cc313f41\n\n# tl;dr\n\nRead our comments to the AI Standardisation Committee constituted by the Department of Telecommunications (DoT) on their paper for the Development of an Indian Artificial Intelligence Stack released on September 2, 2020. Our main recommendation to the committee was to set up an independent supervisory data protection authority to regulate the stack.   \n\n\n# The Indian Artificial Intelligence Stack\n\nOn September 2, 2020, the AI Standardisation Committee constituted by the DoT released the [**paper for the Development of an Indian Artificial Intelligence Stack**](https://ourgovdotin.files.wordpress.com/2020/09/paper-for-development-of-indian-artificial-intelligence-stack.pdf). The paper states that the Government of India has recognised that an AI driven economy, can transform the lives of millions, i.e., AI is the main driver for the desired socio- economic transformation of India. This paper proposes a stack that seeks to remove the impediments to AI deployment by putting in place a comprehensive framework. This will enable development of a suitable AI stack with a different mix of layers and interfaces that complement each other and achieve integration. This paper proposes to divide the AI stack in six different layers with appropriate horizontal and vertical integration. These six layers are:\n\n1. Infrastructure Layer\n2. Storage Layer\n3. Compute Layer\n4. Application Layer\n5. Data / Information Layer\n6. Security &amp; Governance Layer\n\n# Our comments\n\nAfter analysing the paper at length, we came to the conclusion that while the paper highlights certain problems which are generally associated with AI, it fails to provide nuance to these concerns specifically how these concerns will be resolved. Additionally, we also realized that the paper had failed to address one of the most pressing concerns related to AI, i.e, mass surveillance. Thus, we divided our comments into two parts:\n\n## 1. Absence of Nuance\n\nWe noticed that while the paper does point out several concerns with AI, it fails to satisfactorily address these concerns. These concerns mainly relate to:\n\n### Privacy/Security of data collected\n\nThe data being collected by the AI Stack covers a wide range of categories which include sensitive personal data. Paragraph 5.29 of the paper states that “The data processed and stored in many cases include geolocation information, product-identifying data, and personal information related to use or owner identity, such as biometric data, health information, or smart-home metrics. For some applications personal information are also captured through audio or video, or include communication capabilities, such as those used in children’s devices.” The collection of such sensitive personal data raises the obvious question of how will the privacy and data protection issues be resolved. \n\nParagraph 5.3 of the paper states that “In the absence of a clear data protection law in the country, EU's General Data Protection Regulation (GDPR) or any of the laws can be applied. This will serve as interim measure until Indian laws are formalised.”. The Personal Data Protection Bill is currently languishing in the Parliament and it is not known when it will be formalised. However, while the paper does provide for alternatives, it also creates confusion and vagueness as to their applicability. The term “or any of the laws” is unclear and does not indicate which specific laws the paper is pointing to. \n\nThus, the paper puts forward the EU's General Data Protection Regulation (GDPR) as the data protection law which will be applied to the AI Stack. However, the paper fails to address how it will comply with the extensive provisions of the GDPR. One of the requirements under the GDPR is the establishment of a supervisory authority under recital 117 of the GDPR. It is the responsibility of the supervisory authority under recital 122 of the GDPR to ensure that the processing of personal data carried out by public authorities or private bodies acting in the public interest is done in compliance with the principles laid down in GDPR. However, India does not have any such supervisory authority nor does the paper provide for the setting up of one. In the absence of a supervisory authority, enforcement of the GDPR for the AI Stack is not possible. \n\nIn addition to this, certain features of the AI Stack mentioned in the paper are clearly violative of the GDPR. These include paragraph 2.6, which mentions the use of social media data to generate credit scores thereby violating the the conditions of consent laid down in the [**GDPR under article 7**](https://gdpr-info.eu/art-7-gdpr/) and paragraph 5.20, which arbitrarily divides the collected data into three categories (hot data, warm data and cold data) thereby violating the purpose limitation principle as stated in [**Article 5 of the GDPR**](https://gdpr-info.eu/art-5-gdpr/). \n\n### Algorithmic Bias\n\nAnother concern that the paper raises but fails to provide adequate nuance to is how the AI Stack will ensure against algorithmic bias. The paper, in paragraph 4.10, rightly points out that algorithmic bias occurs because “The self learning nature of AI means, the distorted data the AI discovers in search engines, perhaps based upon “unconscious and institutional biases”, and other prejudices, is codified into a matrix that will make decisions for years to come.” As a solution the paper suggests “a need for evolving ethical standards, trustworthiness, and consent framework to get data validation from users.” However, these provisions do not find any mention in the actual proposed stack itself. The paper fails to address how the data/information exchange layer &amp; compute layer will address algorithmic bias and how these layers will ensure that ethical standards are followed in the collection of data and in the building of the algorithm itself. Standards of data collection are also important to ensure that the data collected is sufficiently representative of the population it purports to represent.   \n\n\nFor instance, paragraph 2.5 (a) mentions that access to healthcare can be increased in rural areas with the help of AI and makes the following argument: “This can be achieved through implementation of AI driven diagnostics, personalised treatment, early identification of potential pandemics, and imaging diagnostics, among others.” However, what also needs to be taken into account here is that there exists a massive problem of gender bias not only in [**medical research**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4624369/), but also in [**access to medical help**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2486511/pdf/bullwho00412-0099.pdf). The paper also needs to address and expand on such issues to ensure that existing biases in both medical research and medical access do not creep into the proposed solutions being developed under the AI Stack. To ensure against such occurrences, the AI Now Institute based in New York has released a study titled “[**Algorithmic Impact Assessments: A Practical Framework For Public Agency Accountability**](https://ainowinstitute.org/aiareport2018.pdf)” which introduces a model framework for governmental entities to use to create algorithmic impact assessments (AIAs), which evaluate the potential detrimental effects of an algorithm in the same manner as environmental, privacy, data, or human rights impact statements. Such a safeguard, however, is lacking in the proposed AI Stack.\n\n## 2. Need for the AI Stack to address state surveillance concerns\n\nOne of the major gaps in the paper is its failure to address the concerns surrounding use of AI for state-sponsored mass surveillance. According to a Carnegie Endowment for International Peace working paper titled, “[**The Global Expansion of AI Surveillance**](https://carnegieendowment.org/files/WP-Feldstein-AISurveillance_final1.pdf)” authored by Steven Feldstein, AI surveillance technology is spreading at a faster rate to a wider range of countries than experts have commonly understood. At least seventy-five out of 176 countries globally are actively using AI technologies for surveillance purposes. Liberal democracies (such as India)  are major users of AI surveillance. The index shows that 51 percent of advanced democracies deploy AI surveillance systems. In contrast, 37 percent of closed autocratic states, 41 percent of electoral autocratic/competitive autocratic states, and 41 percent of electoral democracies/illiberal democracies deploy AI surveillance technology. Governments in full democracies are deploying a range of surveillance technology, from safe city platforms to facial recognition cameras.  \n\n\nAs has been reported since December 2019, use of [**facial recognition**](https://internetfreedom.in/is-the-illegal-use-of-facial-recognition-technology-by-the-delhi-police-akin-to-mass-surveillance-you-decide-project-panoptic/) and [**drones**](https://internetfreedom.in/the-ongoing-illegal-use-of-drones-by-the-delhi-police-needs-to-be-investigated/) for surveillance has been rampant in the country and especially in New Delhi. The National Crime Records Bureau’s [**National Automated Facial Recognition System**](https://internetfreedom.in/iffs-legal-notice-to-the-ncrb-on-the-revised-rfp-for-the-national-automated-facial-recognition-system/), which is a central level project aiming to create a national database of photographs which will use facial recognition to identify suspects, is also in the Request for Proposals (RFP) stage. In addition to this, there are multiple other central and state level projects already in place or in development which aim to use AI for security or surveillance purposes. Use of AI for such projects, in the absence of a data protection regime or a concrete surveillance law regime in place raises concerns about misuse. Use of AI for surveillance makes the entire process highly streamlined and cost-effective. According to [**Edward Snowden**](https://variety.com/2019/digital/festivals/idfa-edward-snowden-1203416674/), this allows for the surveillance of teams of people and even populations of people—entire movements, across borders, across languages, across cultures, in other words, state-sponsored mass surveillance.    \n\n\nIn this context, it is pertinent for the AI Stack to also address how such use by the government for surveillance will be regulated by the AI Stack.   \n\n\n# Our recommendations\n\nKeeping in mind the above concerns, we made the following recommendations:  \n\n\n1. An independent supervisory data protection authority consisting of relevant stakeholders should be set-up to regulate the AI Stack. We note that such an authority is presently under contemplation under the Draft Data Protection Bill and should be a condition precedent to the launch and operation of the AI Stack.   \n\n2. The Data Protection Authority  should lay down a privacy framework to ensure the right to privacy of citizens is not violated. The privacy framework should also address how the AI Stack will address the concerns relating to state-sponsored mass surveillance. This can also be a useful body for the harmonisation of standards given the plethora of personal data policies being considered at present by the Union and State Governments.  \n\n3. The Data Protection Authority should also work on expanding how it will ensure against algorithmic bias. For this, the authority should develop an ethical framework for data collection and storage. Some of such provisions are existing within the civil society model titled the Indian Privacy Code, 2020 which has also been introduced in parliament as a private members bill. The specific provision on the need for safeguards when automated decision making leads to legal impacts may be considered. \n\nThese comments were drafted by IFF staff with the help of software engineer [**Gargi Sharma**](https://gs0510.github.io/about/).   \n\n\n# Important Documents\n\n1. Comments to AI Standardisation Committee, Department Of Telecommunications on the paper for Development of an Indian Artificial Intelligence Stack dated October 2, 2020 ([**link**](https://drive.google.com/file/d/1zwcwTWQCAOczC_e_H7oUXbTzUiFUT1XE/view?usp=sharing))\n2. Paper for Development of an Indian Artificial Intelligence Stack dated September 2, 2020 ([**link**](https://ourgovdotin.files.wordpress.com/2020/09/paper-for-development-of-indian-artificial-intelligence-stack.pdf))\n\n[Even during these uncertain times, IFF continues in its operations and working towards protecting your privacy and digital rights. Support us through one time donations or becoming a member with us. Donate now!](https://internetfreedom.in/donate)",
    "flair": "Policy/Economy",
    "score": 26,
    "num_comments": 2,
    "created_utc": 1601702719,
    "convurl": "https://b.thumbs.redditmedia.com/XUkrHC7n1r_BvyTDjp4L3EG-UNJJPhPiUIUpFNT8rNk.jpg",
    "comments": [
        "Can someone please ELI5?",
        "Expect weaponization of Aadhaar for 360° surveillance by the state",
        "You're sounding suspiciously like people who used to say there are microchip in 2000rs note or something"
    ],
    "cleaned_text": "read comments dots paper develop indian ai stack ampxb tldr read comments ai standardisation committee constituted department telecommunications dot paper development indian artificial intelligence stack released september main recommendation committee set independent supervisory data protection authority regulate stack indian artificial intelligence stack september ai standardisation committee constituted dot released paper development indian artificial intelligence stackhttpsourgovdotinfileswordpresscompaperfordevelopmentofindianartificialintelligencestackpdf paper states government india recognised ai driven economy transform lives millions ie ai main driver desired socio economic transformation india paper proposes stack seeks remove impediments ai deployment putting place comprehensive framework enable development suitable ai stack different mix layers interfaces complement achieve integration paper proposes divide ai stack six different layers appropriate horizontal vertical integration six layers infrastructure layer storage layer compute layer application layer data information layer security amp governance layer comments analysing paper length came conclusion paper highlights certain problems generally associated ai fails provide nuance concerns specifically concerns resolved additionally also realized paper failed address one pressing concerns related ai ie mass surveillance thus divided comments two parts absence nuance noticed paper point several concerns ai fails satisfactorily address concerns concerns mainly relate privacysecurity data collected data collected ai stack covers wide range categories include sensitive personal data paragraph paper states data processed stored many cases include geolocation information productidentifying data personal information related use owner identity biometric data health information smarthome metrics applications personal information also captured audio video include communication capabilities used childrens devices collection sensitive personal data raises obvious question privacy data protection issues resolved paragraph paper states absence clear data protection law country eus general data protection regulation gdpr laws applied serve interim measure indian laws formalised personal data protection bill currently languishing parliament known formalised however paper provide alternatives also creates confusion vagueness applicability term laws unclear indicate specific laws paper pointing thus paper puts forward eus general data protection regulation gdpr data protection law applied ai stack however paper fails address comply extensive provisions gdpr one requirements gdpr establishment supervisory authority recital gdpr responsibility supervisory authority recital gdpr ensure processing personal data carried public authorities private bodies acting public interest done compliance principles laid gdpr however india supervisory authority paper provide setting one absence supervisory authority enforcement gdpr ai stack possible addition certain features ai stack mentioned paper clearly violative gdpr include paragraph mentions use social media data generate credit scores thereby violating conditions consent laid gdpr article httpsgdprinfoeuartgdpr paragraph arbitrarily divides collected data three categories hot data warm data cold data thereby violating purpose limitation principle stated article gdprhttpsgdprinfoeuartgdpr algorithmic bias another concern paper raises fails provide adequate nuance ai stack ensure algorithmic bias paper paragraph rightly points algorithmic bias occurs self learning nature ai means distorted data ai discovers search engines perhaps based upon unconscious institutional biases prejudices codified matrix make decisions years come solution paper suggests need evolving ethical standards trustworthiness consent framework get data validation users however provisions find mention actual proposed stack paper fails address datainformation exchange layer amp compute layer address algorithmic bias layers ensure ethical standards followed collection data building algorithm standards data collection also important ensure data collected sufficiently representative population purports represent instance paragraph mentions access healthcare increased rural areas help ai makes following argument achieved implementation ai driven diagnostics personalised treatment early identification potential pandemics imaging diagnostics among others however also needs taken account exists massive problem gender bias medical researchhttpswwwncbinlmnihgovpmcarticlespmc also access medical helphttpswwwncbinlmnihgovpmcarticlespmcpdfbullwhopdf paper also needs address expand issues ensure existing biases medical research medical access creep proposed solutions developed ai stack ensure occurrences ai institute based new york released study titled algorithmic impact assessments practical framework public agency accountabilityhttpsainowinstituteorgaiareportpdf introduces model framework governmental entities use create algorithmic impact assessments aias evaluate potential detrimental effects algorithm manner environmental privacy data human rights impact statements safeguard however lacking proposed ai stack need ai stack address state surveillance concerns one major gaps paper failure address concerns surrounding use ai statesponsored mass surveillance according carnegie endowment international peace working paper titled global expansion ai surveillancehttpscarnegieendowmentorgfileswpfeldsteinaisurveillancefinalpdf authored steven feldstein ai surveillance technology spreading faster rate wider range countries experts commonly understood least seventyfive countries globally actively using ai technologies surveillance purposes liberal democracies india major users ai surveillance index shows percent advanced democracies deploy ai surveillance systems contrast percent closed autocratic states percent electoral autocraticcompetitive autocratic states percent electoral democraciesilliberal democracies deploy ai surveillance technology governments full democracies deploying range surveillance technology safe city platforms facial recognition cameras reported since december use facial recognitionhttpsinternetfreedoministheillegaluseoffacialrecognitiontechnologybythedelhipoliceakintomasssurveillanceyoudecideprojectpanoptic droneshttpsinternetfreedomintheongoingillegaluseofdronesbythedelhipoliceneedstobeinvestigated surveillance rampant country especially new delhi national crime records bureaus national automated facial recognition systemhttpsinternetfreedominiffslegalnoticetothencrbontherevisedrfpforthenationalautomatedfacialrecognitionsystem central level project aiming create national database photographs use facial recognition identify suspects also request proposals rfp stage addition multiple central state level projects already place development aim use ai security surveillance purposes use ai projects absence data protection regime concrete surveillance law regime place raises concerns misuse use ai surveillance makes entire process highly streamlined costeffective according edward snowdenhttpsvarietycomdigitalfestivalsidfaedwardsnowden allows surveillance teams people even populations peopleentire movements across borders across languages across cultures words statesponsored mass surveillance context pertinent ai stack also address use government surveillance regulated ai stack recommendations keeping mind concerns made following recommendations independent supervisory data protection authority consisting relevant stakeholders setup regulate ai stack note authority presently contemplation draft data protection bill condition precedent launch operation ai stack data protection authority lay privacy framework ensure right privacy citizens violated privacy framework also address ai stack address concerns relating statesponsored mass surveillance also useful body harmonisation standards given plethora personal data policies considered present union state governments data protection authority also work expanding ensure algorithmic bias authority develop ethical framework data collection storage provisions existing within civil society model titled indian privacy code also introduced parliament private members bill specific provision need safeguards automated decision making leads legal impacts may considered comments drafted iff staff help software engineer gargi sharmahttpsgsgithubioabout important documents comments ai standardisation committee department telecommunications paper development indian artificial intelligence stack dated october linkhttpsdrivegooglecomfiledzwcwtwqcaoczcehouxbtzuifutxeviewuspsharing paper development indian artificial intelligence stack dated september linkhttpsourgovdotinfileswordpresscompaperfordevelopmentofindianartificialintelligencestackpdf even uncertain times iff continues operations working towards protecting privacy digital rights support us one time donations becoming member us donate nowhttpsinternetfreedomindonate ",
    "cleaned_title": "read comments dots paper develop indian ai stack",
    "cleaned_selftext": "ampxb tldr read comments ai standardisation committee constituted department telecommunications dot paper development indian artificial intelligence stack released september main recommendation committee set independent supervisory data protection authority regulate stack indian artificial intelligence stack september ai standardisation committee constituted dot released paper development indian artificial intelligence stackhttpsourgovdotinfileswordpresscompaperfordevelopmentofindianartificialintelligencestackpdf paper states government india recognised ai driven economy transform lives millions ie ai main driver desired socio economic transformation india paper proposes stack seeks remove impediments ai deployment putting place comprehensive framework enable development suitable ai stack different mix layers interfaces complement achieve integration paper proposes divide ai stack six different layers appropriate horizontal vertical integration six layers infrastructure layer storage layer compute layer application layer data information layer security amp governance layer comments analysing paper length came conclusion paper highlights certain problems generally associated ai fails provide nuance concerns specifically concerns resolved additionally also realized paper failed address one pressing concerns related ai ie mass surveillance thus divided comments two parts absence nuance noticed paper point several concerns ai fails satisfactorily address concerns concerns mainly relate privacysecurity data collected data collected ai stack covers wide range categories include sensitive personal data paragraph paper states data processed stored many cases include geolocation information productidentifying data personal information related use owner identity biometric data health information smarthome metrics applications personal information also captured audio video include communication capabilities used childrens devices collection sensitive personal data raises obvious question privacy data protection issues resolved paragraph paper states absence clear data protection law country eus general data protection regulation gdpr laws applied serve interim measure indian laws formalised personal data protection bill currently languishing parliament known formalised however paper provide alternatives also creates confusion vagueness applicability term laws unclear indicate specific laws paper pointing thus paper puts forward eus general data protection regulation gdpr data protection law applied ai stack however paper fails address comply extensive provisions gdpr one requirements gdpr establishment supervisory authority recital gdpr responsibility supervisory authority recital gdpr ensure processing personal data carried public authorities private bodies acting public interest done compliance principles laid gdpr however india supervisory authority paper provide setting one absence supervisory authority enforcement gdpr ai stack possible addition certain features ai stack mentioned paper clearly violative gdpr include paragraph mentions use social media data generate credit scores thereby violating conditions consent laid gdpr article httpsgdprinfoeuartgdpr paragraph arbitrarily divides collected data three categories hot data warm data cold data thereby violating purpose limitation principle stated article gdprhttpsgdprinfoeuartgdpr algorithmic bias another concern paper raises fails provide adequate nuance ai stack ensure algorithmic bias paper paragraph rightly points algorithmic bias occurs self learning nature ai means distorted data ai discovers search engines perhaps based upon unconscious institutional biases prejudices codified matrix make decisions years come solution paper suggests need evolving ethical standards trustworthiness consent framework get data validation users however provisions find mention actual proposed stack paper fails address datainformation exchange layer amp compute layer address algorithmic bias layers ensure ethical standards followed collection data building algorithm standards data collection also important ensure data collected sufficiently representative population purports represent instance paragraph mentions access healthcare increased rural areas help ai makes following argument achieved implementation ai driven diagnostics personalised treatment early identification potential pandemics imaging diagnostics among others however also needs taken account exists massive problem gender bias medical researchhttpswwwncbinlmnihgovpmcarticlespmc also access medical helphttpswwwncbinlmnihgovpmcarticlespmcpdfbullwhopdf paper also needs address expand issues ensure existing biases medical research medical access creep proposed solutions developed ai stack ensure occurrences ai institute based new york released study titled algorithmic impact assessments practical framework public agency accountabilityhttpsainowinstituteorgaiareportpdf introduces model framework governmental entities use create algorithmic impact assessments aias evaluate potential detrimental effects algorithm manner environmental privacy data human rights impact statements safeguard however lacking proposed ai stack need ai stack address state surveillance concerns one major gaps paper failure address concerns surrounding use ai statesponsored mass surveillance according carnegie endowment international peace working paper titled global expansion ai surveillancehttpscarnegieendowmentorgfileswpfeldsteinaisurveillancefinalpdf authored steven feldstein ai surveillance technology spreading faster rate wider range countries experts commonly understood least seventyfive countries globally actively using ai technologies surveillance purposes liberal democracies india major users ai surveillance index shows percent advanced democracies deploy ai surveillance systems contrast percent closed autocratic states percent electoral autocraticcompetitive autocratic states percent electoral democraciesilliberal democracies deploy ai surveillance technology governments full democracies deploying range surveillance technology safe city platforms facial recognition cameras reported since december use facial recognitionhttpsinternetfreedoministheillegaluseoffacialrecognitiontechnologybythedelhipoliceakintomasssurveillanceyoudecideprojectpanoptic droneshttpsinternetfreedomintheongoingillegaluseofdronesbythedelhipoliceneedstobeinvestigated surveillance rampant country especially new delhi national crime records bureaus national automated facial recognition systemhttpsinternetfreedominiffslegalnoticetothencrbontherevisedrfpforthenationalautomatedfacialrecognitionsystem central level project aiming create national database photographs use facial recognition identify suspects also request proposals rfp stage addition multiple central state level projects already place development aim use ai security surveillance purposes use ai projects absence data protection regime concrete surveillance law regime place raises concerns misuse use ai surveillance makes entire process highly streamlined costeffective according edward snowdenhttpsvarietycomdigitalfestivalsidfaedwardsnowden allows surveillance teams people even populations peopleentire movements across borders across languages across cultures words statesponsored mass surveillance context pertinent ai stack also address use government surveillance regulated ai stack recommendations keeping mind concerns made following recommendations independent supervisory data protection authority consisting relevant stakeholders setup regulate ai stack note authority presently contemplation draft data protection bill condition precedent launch operation ai stack data protection authority lay privacy framework ensure right privacy citizens violated privacy framework also address ai stack address concerns relating statesponsored mass surveillance also useful body harmonisation standards given plethora personal data policies considered present union state governments data protection authority also work expanding ensure algorithmic bias authority develop ethical framework data collection storage provisions existing within civil society model titled indian privacy code also introduced parliament private members bill specific provision need safeguards automated decision making leads legal impacts may considered comments drafted iff staff help software engineer gargi sharmahttpsgsgithubioabout important documents comments ai standardisation committee department telecommunications paper development indian artificial intelligence stack dated october linkhttpsdrivegooglecomfiledzwcwtwqcaoczcehouxbtzuifutxeviewuspsharing paper development indian artificial intelligence stack dated september linkhttpsourgovdotinfileswordpresscompaperfordevelopmentofindianartificialintelligencestackpdf even uncertain times iff continues operations working towards protecting privacy digital rights support us one time donations becoming member us donate nowhttpsinternetfreedomindonate",
    "cleaned_comments": "someone please eli expect weaponization aadhaar surveillance state youre sounding suspiciously like people used say microchip rs note something",
    "light_cleaned_title": "Read our comments on the DoT's Paper to develop an Indian AI Stack",
    "light_cleaned_selftext": "# tl;dr Read our comments to the AI Standardisation Committee constituted by the Department of Telecommunications (DoT) on their paper for the Development of an Indian Artificial Intelligence Stack released on September 2, 2020. Our main recommendation to the committee was to set up an independent supervisory data protection authority to regulate the stack. # The Indian Artificial Intelligence Stack On September 2, 2020, the AI Standardisation Committee constituted by the DoT released the [**paper for the Development of an Indian Artificial Intelligence Stack**](https://ourgovdotin.files.wordpress.com/2020/09/paper-for-development-of-indian-artificial-intelligence-stack.pdf). The paper states that the Government of India has recognised that an AI driven economy, can transform the lives of millions, i.e., AI is the main driver for the desired socio- economic transformation of India. This paper proposes a stack that seeks to remove the impediments to AI deployment by putting in place a comprehensive framework. This will enable development of a suitable AI stack with a different mix of layers and interfaces that complement each other and achieve integration. This paper proposes to divide the AI stack in six different layers with appropriate horizontal and vertical integration. These six layers are: 1. Infrastructure Layer 2. Storage Layer 3. Compute Layer 4. Application Layer 5. Data / Information Layer 6. Security &amp; Governance Layer # Our comments After analysing the paper at length, we came to the conclusion that while the paper highlights certain problems which are generally associated with AI, it fails to provide nuance to these concerns specifically how these concerns will be resolved. Additionally, we also realized that the paper had failed to address one of the most pressing concerns related to AI, i.e, mass surveillance. Thus, we divided our comments into two parts: ## 1. Absence of Nuance We noticed that while the paper does point out several concerns with AI, it fails to satisfactorily address these concerns. These concerns mainly relate to: ### Privacy/Security of data collected The data being collected by the AI Stack covers a wide range of categories which include sensitive personal data. Paragraph 5.29 of the paper states that “The data processed and stored in many cases include geolocation information, product-identifying data, and personal information related to use or owner identity, such as biometric data, health information, or smart-home metrics. For some applications personal information are also captured through audio or video, or include communication capabilities, such as those used in children’s devices.” The collection of such sensitive personal data raises the obvious question of how will the privacy and data protection issues be resolved. Paragraph 5.3 of the paper states that “In the absence of a clear data protection law in the country, EU's General Data Protection Regulation (GDPR) or any of the laws can be applied. This will serve as interim measure until Indian laws are formalised.”. The Personal Data Protection Bill is currently languishing in the Parliament and it is not known when it will be formalised. However, while the paper does provide for alternatives, it also creates confusion and vagueness as to their applicability. The term “or any of the laws” is unclear and does not indicate which specific laws the paper is pointing to. Thus, the paper puts forward the EU's General Data Protection Regulation (GDPR) as the data protection law which will be applied to the AI Stack. However, the paper fails to address how it will comply with the extensive provisions of the GDPR. One of the requirements under the GDPR is the establishment of a supervisory authority under recital 117 of the GDPR. It is the responsibility of the supervisory authority under recital 122 of the GDPR to ensure that the processing of personal data carried out by public authorities or private bodies acting in the public interest is done in compliance with the principles laid down in GDPR. However, India does not have any such supervisory authority nor does the paper provide for the setting up of one. In the absence of a supervisory authority, enforcement of the GDPR for the AI Stack is not possible. In addition to this, certain features of the AI Stack mentioned in the paper are clearly violative of the GDPR. These include paragraph 2.6, which mentions the use of social media data to generate credit scores thereby violating the the conditions of consent laid down in the [**GDPR under article 7**](https://gdpr-info.eu/art-7-gdpr/) and paragraph 5.20, which arbitrarily divides the collected data into three categories (hot data, warm data and cold data) thereby violating the purpose limitation principle as stated in [**Article 5 of the GDPR**](https://gdpr-info.eu/art-5-gdpr/). ### Algorithmic Bias Another concern that the paper raises but fails to provide adequate nuance to is how the AI Stack will ensure against algorithmic bias. The paper, in paragraph 4.10, rightly points out that algorithmic bias occurs because “The self learning nature of AI means, the distorted data the AI discovers in search engines, perhaps based upon “unconscious and institutional biases”, and other prejudices, is codified into a matrix that will make decisions for years to come.” As a solution the paper suggests “a need for evolving ethical standards, trustworthiness, and consent framework to get data validation from users.” However, these provisions do not find any mention in the actual proposed stack itself. The paper fails to address how the data/information exchange layer &amp; compute layer will address algorithmic bias and how these layers will ensure that ethical standards are followed in the collection of data and in the building of the algorithm itself. Standards of data collection are also important to ensure that the data collected is sufficiently representative of the population it purports to represent. For instance, paragraph 2.5 (a) mentions that access to healthcare can be increased in rural areas with the help of AI and makes the following argument: “This can be achieved through implementation of AI driven diagnostics, personalised treatment, early identification of potential pandemics, and imaging diagnostics, among others.” However, what also needs to be taken into account here is that there exists a massive problem of gender bias not only in [**medical research**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4624369/), but also in [**access to medical help**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2486511/pdf/bullwho00412-0099.pdf). The paper also needs to address and expand on such issues to ensure that existing biases in both medical research and medical access do not creep into the proposed solutions being developed under the AI Stack. To ensure against such occurrences, the AI Now Institute based in New York has released a study titled “[**Algorithmic Impact Assessments: A Practical Framework For Public Agency Accountability**](https://ainowinstitute.org/aiareport2018.pdf)” which introduces a model framework for governmental entities to use to create algorithmic impact assessments (AIAs), which evaluate the potential detrimental effects of an algorithm in the same manner as environmental, privacy, data, or human rights impact statements. Such a safeguard, however, is lacking in the proposed AI Stack. ## 2. Need for the AI Stack to address state surveillance concerns One of the major gaps in the paper is its failure to address the concerns surrounding use of AI for state-sponsored mass surveillance. According to a Carnegie Endowment for International Peace working paper titled, “[**The Global Expansion of AI Surveillance**](https://carnegieendowment.org/files/WP-Feldstein-AISurveillance_final1.pdf)” authored by Steven Feldstein, AI surveillance technology is spreading at a faster rate to a wider range of countries than experts have commonly understood. At least seventy-five out of 176 countries globally are actively using AI technologies for surveillance purposes. Liberal democracies (such as India) are major users of AI surveillance. The index shows that 51 percent of advanced democracies deploy AI surveillance systems. In contrast, 37 percent of closed autocratic states, 41 percent of electoral autocratic/competitive autocratic states, and 41 percent of electoral democracies/illiberal democracies deploy AI surveillance technology. Governments in full democracies are deploying a range of surveillance technology, from safe city platforms to facial recognition cameras. As has been reported since December 2019, use of [**facial recognition**](https://internetfreedom.in/is-the-illegal-use-of-facial-recognition-technology-by-the-delhi-police-akin-to-mass-surveillance-you-decide-project-panoptic/) and [**drones**](https://internetfreedom.in/the-ongoing-illegal-use-of-drones-by-the-delhi-police-needs-to-be-investigated/) for surveillance has been rampant in the country and especially in New Delhi. The National Crime Records Bureau’s [**National Automated Facial Recognition System**](https://internetfreedom.in/iffs-legal-notice-to-the-ncrb-on-the-revised-rfp-for-the-national-automated-facial-recognition-system/), which is a central level project aiming to create a national database of photographs which will use facial recognition to identify suspects, is also in the Request for Proposals (RFP) stage. In addition to this, there are multiple other central and state level projects already in place or in development which aim to use AI for security or surveillance purposes. Use of AI for such projects, in the absence of a data protection regime or a concrete surveillance law regime in place raises concerns about misuse. Use of AI for surveillance makes the entire process highly streamlined and cost-effective. According to [**Edward Snowden**](https://variety.com/2019/digital/festivals/idfa-edward-snowden-1203416674/), this allows for the surveillance of teams of people and even populations of people—entire movements, across borders, across languages, across cultures, in other words, state-sponsored mass surveillance. In this context, it is pertinent for the AI Stack to also address how such use by the government for surveillance will be regulated by the AI Stack. # Our recommendations Keeping in mind the above concerns, we made the following recommendations: 1. An independent supervisory data protection authority consisting of relevant stakeholders should be set-up to regulate the AI Stack. We note that such an authority is presently under contemplation under the Draft Data Protection Bill and should be a condition precedent to the launch and operation of the AI Stack. 2. The Data Protection Authority should lay down a privacy framework to ensure the right to privacy of citizens is not violated. The privacy framework should also address how the AI Stack will address the concerns relating to state-sponsored mass surveillance. This can also be a useful body for the harmonisation of standards given the plethora of personal data policies being considered at present by the Union and State Governments. 3. The Data Protection Authority should also work on expanding how it will ensure against algorithmic bias. For this, the authority should develop an ethical framework for data collection and storage. Some of such provisions are existing within the civil society model titled the Indian Privacy Code, 2020 which has also been introduced in parliament as a private members bill. The specific provision on the need for safeguards when automated decision making leads to legal impacts may be considered. These comments were drafted by IFF staff with the help of software engineer [**Gargi Sharma**](https://gs0510.github.io/about/). # Important Documents 1. Comments to AI Standardisation Committee, Department Of Telecommunications on the paper for Development of an Indian Artificial Intelligence Stack dated October 2, 2020 ([**link**](https://drive.google.com/file/d/1zwcwTWQCAOczC_e_H7oUXbTzUiFUT1XE/view?usp=sharing)) 2. Paper for Development of an Indian Artificial Intelligence Stack dated September 2, 2020 ([**link**](https://ourgovdotin.files.wordpress.com/2020/09/paper-for-development-of-indian-artificial-intelligence-stack.pdf)) [Even during these uncertain times, IFF continues in its operations and working towards protecting your privacy and digital rights. Support us through one time donations or becoming a member with us. Donate now!](https://internetfreedom.in/donate)",
    "light_cleaned_comments": "Can someone please ELI5? Expect weaponization of Aadhaar for 360° surveillance by the state You're sounding suspiciously like people who used to say there are microchip in 2000rs note or something"
}