{
    "id": "1cxvmrs",
    "title": "Why a massive leak in Tamil Nadu Police’s Facial Recognition Portal database must herald the end of police use of surveillance technologies | #BanTheScan",
    "url": "https://www.reddit.com/r/india/comments/1cxvmrs/why_a_massive_leak_in_tamil_nadu_polices_facial/",
    "selftext": "[IFF needs your support, now more than ever. Details at the end of this post.](https://preview.redd.it/8wb4pwopyx1d1.png?width=1600&format=png&auto=webp&s=c37b22ad8c1c3099c2acbb936b8cb8139dbc88f3)\n\n# tl;dr\n\nA massive leak in the Tamil Nadu police’s Facial Recognition Portal has revealed many scary truths. Not only is centrally stored facial biometric data of suspects and criminals an *ipso facto* violation of their privacy and human rights, but it is also not securely stored or adequately regulated under Indian law. The blatant lack of checks and balances on how law enforcement uses surveillance tools like FRT also makes such criminal identification systems breeding grounds for discrimination, targeted policing, and disenfranchisement of historically marginalised groups. This post explores the recent data leak, how FRT systems work in criminal investigations, and the law (or lack thereof) to regulate it; and also calls attention to a significant global campaign #BanTheScan, which in context of how Indian police forces use FRT, is the need of the hour.\n\n# Background\n\nOn May 4, 2024, threat intelligence platform [FalconFeeds.io](http://FalconFeeds.io) [~reported~](https://x.com/FalconFeedsio/status/1786614640908304764?ref=static.internetfreedom.in) a massive breach in Tamil Nadu (“**TN**”) Police’s Facial Recognition Portal, which exposed over 8,00,000 lines of data, including match reports from their Facial Recognition System (“**FRS**”). Other categories of leaked data [~include~](https://www.medianama.com/2024/05/223-tamil-nadu-police-facial-recognition-portal-data-breach-exposes-over-50000-users-details/?ref=static.internetfreedom.in):\n\n* **Police officer Data:** 54,828 users’ personally identifiable information, including user ID, user name, first name, last name, police station, district, contact, last login, date joined, active status, staff status, superuser status, login type(s), verified person type(s);\n* **Police Station Data:** 2,738 police stations’ data, including the police station ID, police station name, code, district, district code, pin code, contact details;\n* **Police ID data:** 54,934 users’ data, including user ID, image, user name, first name, last name, police station name, district, email address;\n* **FIR Data:** 8,98,352 FIRs with FIR ID, NIC FIR number, FIR number, person category, police station, district, investigating officer, launch date, occurrence date, stage of the case, name in FIR, age, gender, parentage, address;\n* **Alert Data:** 235,753 Searches/Alerts made by police officers, along with the following data: Alert ID, alert against the query, query fir, alert against fir, source police station, source district, target police station, target district, alert result, not matched reason, alert made by, launch date, back date, initial comment, alert state.\n\nThe TN police promptly responded through a [~press release~](https://pbs.twimg.com/media/GMvD9UEasAERfGP?format=jpg&name=large&ref=static.internetfreedom.in) the same day, claiming that the password of an admin account was compromised and has since been deactivated. They stated that the last security audit of the portal was carried out by Tamil Nadu e-Governance Agency (“**TNeGA**”) on March 13, 2024. As a preventive measure, the TN police have deactivated the admin account. They [~claimed~](https://www.newindianexpress.com/states/tamil-nadu/2024/May/05/tamil-nadu-polices-face-recognition-portal-hacked-fir-personal-information-up-for-sale?ref=static.internetfreedom.in) that unauthorised users can view only the front end data (like creation of ID for users, queries search) and hence could not have accessed the backend data or main server data. They added that a complaint has been filed at the Cyber Crime Police Station, Chennai and key departments have been notified of the leak for further action.\n\n# How does the FRS work?\n\nThe FRS portal and software used by the TN Police was [~developed~](https://www.cdac.in/index.aspx?id=pk_itn_spot1274&ref=static.internetfreedom.in) by the Centre for Development of Advanced Computing (“**CDAC**”), Kolkata division, and hosted on the server at Tamil Nadu State Data Centre, Electronics Corporation of Tamil Nadu (“**TNSDC-ELCOT**”). It generated Facial Recognition Reports each time a police officer ran a query image (i.e. picture of the person to be identified). The software helps the TN Police to capture the images of wanted persons, missing persons, and unidentified corpses from the central Crime and Criminal Tracking Network and Systems (“**CCTNS**”) [~database~](https://www.digitalpolicecitizenservices.gov.in/?ref=static.internetfreedom.in). The portal, comprising all the facial biometric data and reports, is used by 46,112 users across Tamil Nadu. This is the interface that suffered a leak through a compromised password.\n\nIn 2021, we [~analysed~](https://internetfreedom.in/from-investigation-to-conviction-how-does-the-police-use-frt/?ref=static.internetfreedom.in) how Indian police forces use facial recognition technology (“**FRT**”). Police forces use it for two primary purposes—verification and identification. Verification, or authentication, is done by matching the live photograph of a person to the pre-existing photograph that has been uploaded on any government FRT database. This is to ensure that the person presented is who they are claiming to be, and is also called 1:1 matching. This is more ubiquitous among government administrative departments, which use FRT to authenticate the identity of an individual seeking to gain access to any benefits or government schemes. \n\nIdentification, on the other hand, is heavily relied on by police forces for rounding up criminals and suspects. This is done by trying to get a match between the face of an individual (usually a suspect) which has been extracted from a photograph/video or taken at the police station, with the entire criminal database maintained by the state police, in order to ascertain the identity of the individual. This is also called 1:many matching. Usually, the FRS used by the police will produce reports with a list of close matches (also called a probability match score or a confidence score) between the suspect who is to be identified and the pre-existing FRT database. For the TN police, as for many other state police systems, the CCTNS serves as a central storage of all such facial data that the suspect can be matched against. Read our critical analysis of the CCTNS storage and tracking system and its surveillance and privacy concerns [~here~](https://static.internetfreedom.in/watch-the-watchmen-part-3/). \n\nIn every such FRS match report, multiple possible matches are generated and listed on the basis of their likelihood to be the correct match with corresponding confidence scores. The final identification, however, is done by the police officer, who selects one match from the list of matches generated by the technology. This identification procedure has been [~globally critiqued~](http://hrlr.law.columbia.edu/hrlr-online/you-can-see-my-face-why-cant-i-facial-recognition-and-brady/?ref=static.internetfreedom.in) to be ripe for misidentification because, while the software releases several possible matches, the police officer or ‘human analyst’ conducting the search makes the final identification.\n\nSuch a methodology also opens the door for the police officers’ own biases to creep into the final result wherein they may be prejudiced against a certain race, religion, or community, based on which their decision making may be affected. Indian police forces have a [~deep history~](https://longreads.tni.org/stateofpower/settled-habits-new-tricks-casteist-policing-meets-big-tech-in-india?ref=static.internetfreedom.in) of institutionalised biases and targeted policing against certain minorities, and many existing police databases reflect these biases. Relying on these cryptic technologies (that are impossible for most common men to understand) to make significant law enforcement decisions such as identifying criminals and making arrests, can legitimise the existing biassed data and absolve police forces and officers of any accountability.\n\n# But does it even work?\n\nThe accuracy rates generated by the FRT depend on a [~number of factors~](http://hrlr.law.columbia.edu/hrlr-online/you-can-see-my-face-why-cant-i-facial-recognition-and-brady/?ref=static.internetfreedom.in)—camera quality, light, distance, database size, algorithm, and the suspect’s race and gender, to name a few. Advanced systems around the globe can achieve accuracy rates of 90%, but that still means that chances of misidentification are 10%, which is high enough. Misidentification, or false positives, occur when a person is identified as someone they are not. This is especially concerning as it can lead to the police pursuing and charging innocent persons for a crime they did not commit. And as existing police databases are flawed and biassed, the chances of implicating persons belonging to certain minorities or marginalisations also become high. \n\nThis is markedly different from identification through other kinds of biometric prints like fingerprints or DNA samples. As [~research~](https://www.nacdl.org/getattachment/548c697c-fd8e-4b8d-b4c3-2540336fad94/challenging-facial-recognition-software-in-criminal-court_july-2019.pdf?ref=static.internetfreedom.in) done at National Association of Criminal Defense Lawyers shows, “*(i)f the sample is contaminated or does not have enough of the biometric data, either insufficient DNA or a partial latent fingerprint, the result is inconclusive. Facial recognition is different; even if the matches include the correct suspect, the analyst conducting the search and selecting the match to forward to investigators may choose the wrong individual. The correct match may not even be in the list of results identified by the software, but the analyst reviewing the results may find a match anyway, thereby implicating an innocent person (a false positive)*.” \n\nFurther, we have found through Right to Information (“**RTI**”) requests that police forces in India have [~low accuracy rates~](https://internetfreedom.in/delhi-polices-frt-use-is-80-accurate-and-100-scary/?ref=static.internetfreedom.in) while deploying FRT. The accuracy of their FRT depends on light conditions, distance, and angle of face. For the Delhi police, all matches above 80% similarity are treated as positive results while matches below 80% similarity are treated as false positive results which require additional “corroborative evidence”. It is unclear (and astounding) why 80% is chosen as the threshold above which a match will be “positive” and that an above 80% match score is sufficient to assume the results are correct and no justification has been provided for this classification. Moreover, the distinction between categorisation of below 80% results as false positive instead of negative shows that the Delhi police may still try to use below 80% results for further investigation by trying other methods of “corroborative evidence”. \n\nThis means that, even if the technology does not give a sufficient enough result, the police may continue to investigate anyone who may have gotten a very low match score. By this logic, any person who looks even slightly similar could end up being targeted, raising concerns for people from historically marginalised communities. Further, according to a [~submission~](https://www.business-standard.com/article/pti-stories/delhi-police-facial-recognition-software-has-only-2-per-cent-accuracy-hc-told-118082301289_1.html?ref=static.internetfreedom.in) made before the High Court of Delhi, the accuracy rate of the FRT being used by the Delhi Police is 2%. TWO PERCENT!!!\n\nInaccuracy, however, is not an Indian problem which can be solved with “better” technology. According to a [~report~](https://www.perpetuallineup.org/findings/accuracy?ref=static.internetfreedom.in) by Georgetown Law’s Center on Privacy and Technology, the FBI’s [~own statistics~](https://www.theguardian.com/world/2016/oct/18/police-facial-recognition-database-surveillance-profiling?ref=static.internetfreedom.in) suggest that one out of every seven searches of its facial recognition database fails to turn up a correct match, meaning the software occasionally produces 50 “potential” matches who are all “innocent”. While we do not have any complete information about all FRT systems in India and their respective accuracy rates due to a lack of transparency on the part of the government authorities, it is safe to assume that their accuracy rates will be significantly lower than the [~FBI’s~](https://www.gao.gov/products/gao-19-579t?ref=static.internetfreedom.in#:~:text=Additional%20Work%20Remains-,Face%20Recognition%20Technology%3A%20DOJ%20and%20FBI%20Have%20Taken%20Some%20Actions,Published%3A%20Jun%2004%2C%202019.&text=The%20FBI's%20face%20recognition%20office,photos%2C%20including%2021%20state%20databases) 86% accuracy rate… which, unlike Delhi or TN police, has access to the most advanced technology in the world. \n\n# But all this can be prevented by the law right? Right???\n\nAs it stands today, use of FRT or any surveillance systems is not regulated by any law in force in India. There are no standards, guidelines, circulars, policy documents, or even internal office memorandum (at least in the public domain) in place to regulate the technology or certify its quality or accuracy. Yet, police forces are increasingly becoming the [~largest deployers~](https://www.medianama.com/2023/04/223-growing-use-drones-police/?ref=static.internetfreedom.in) of various surveillance tools. It is not far-fetched to think that the FRS being deployed by them is sub-par in quality and may easily lead to misidentification, and ultimately, false convictions.\n\nEven when the Digital Personal Data Protection Act, 2023 (“**DPDPA**”) comes into play with its procedural Rules notified, it still may not be able to adequately protect the sensitive facial biometric data of suspects or criminals in the system, or regulate its use by police forces. This is for two reasons. \n\n1. Section 17 of the Act holds the power to exempt government instrumentalities and law enforcement agencies from its very application at any given time. It is highly likely that such an exemption will be afforded to police forces, as law enforcement is often given far and wide regulatory exemptions for purposes of maintaining public order, safety, or security. The valuable provisions of seeking informed and verifiable consent before data sharing, among others, will not apply to police use of FRT.\n2. The DPDPA does not classify ‘sensitive personal data’ as a distinct category needing additional safeguards and caution, like its earlier versions or even the Information Technology (*Reasonable Security Practices and Procedures and Sensitive Personal Data or Information*) Rules, 2011. Global instruments recognise the sensitive nature of biometric information such as facial data and the vulnerable position the processing of such data may leave the data principles in. As the European Council’s ‘[~Guidelines on facial recognition~](https://rm.coe.int/guidelines-facial-recognition-web-a5-2750-3427-6868-1/1680a31751?ref=static.internetfreedom.in)’ recognise, \n\n>“*Considering the potential intrusiveness of these \\[facial recognition\\] technologies, legislators and decision makers have to ensure that an explicit and precise legal basis provides the necessary safeguards for the processing of biometric data. Such a legal basis will include the strict necessity and proportionality of their use and will take into consideration the vulnerability of the data subjects and the nature of the environment in which these technologies are used for verification purposes.*”\n\nTherefore, until specific Rules under the DPDPA prescribe higher standards for processing sensitive information such as facial biometric data, criminal FRS across India will continue to operate without appropriate privacy safeguards.\n\nIt is pertinent to note that the TN police attempts to legitimise their use of FRS by drawing powers to identify criminals under the Tamil Nadu District Police Act, 1859 and the Code of Criminal Procedure, 1973. They have been using this wide interpretation of policing powers to [~actively progress~](https://www.thenewsminute.com/article/chennai-police-s-use-facial-recognition-technology-commuter-draws-flak-170753?ref=static.internetfreedom.in) towards installing and deploying FRT systems across the state. For instance, by April 2022, the government had equipped over 40,000 personnel in the field and police stations with FRTs, and since 2018, the government has installed facial recognition-enabled CCTV cameras in 100 “crime-sensitive” locations and had commenced operating the technology in Kancheepuram and Madurai as of March 2022.\n\nHowever, the constitutional validity of TN police’s legal interpretation and use of FRT ubiquitous is under [~legal challenge~](https://internetfreedom.in/tamil-nadu-frt-challenge/?ref=static.internetfreedom.in), where the petitioner is assisted by IFF. We have challenged the deployment on the grounds that a) the Supreme Court in [*~K.S. Puttaswamy v. Union of India & Ors~*](https://indiankanoon.org/doc/91938676/?ref=static.internetfreedom.in) *(2017) 10 SCC 1* has held that the government cannot curtail the right to privacy unless such restriction is grounded in law, and is necessary and proportionate; and the manner of implementation of the FRT infringes the right to privacy, as it fails the five-pronged proportionality test laid by the Supreme Court; b) it lacks legislative authorisation and thus, fails the test of legality, as the reliance placed on Tamil Nadu District Police Act of 1859 and Code of Criminal Procedure of 1973 is inherently flawed; c) even if it is held that the FRT is sufficiently grounded within existing legislation, it still fails the other prongs of proportionality requirement, specifically, rationality, necessity, balancing and safeguards against abuse; and d) the deployment of FRT is demonstrably discriminatory in nature, and hence, without prior impact assessment, it violates Article 14 of the Constitution. We await the next date of hearing in the matter.\n\n# It is time to #BanTheScan\n\nWe know that FRT used by police forces is not accurate. We know that it can lead to rights violations and disenfranchisement of historically marginalised groups. We know that it is deployed without legal safeguards or checks and balances. After the massive leak in the TN FRS portal, we now know that this facial data collected in vast numbers, is also not secure. Given that the privacy and human rights violations and surveillance concerns associated with criminal FRS far outweigh its benefits, it is time that police forces stop using it altogether. \n\nA similar demand is echoed in Amnesty International’s [~Ban The Scan~](https://banthescan.amnesty.org/hyderabad/?ref=static.internetfreedom.in) campaign, which is a call to completely withdraw all private and public use of FRS owing to the high risks associated with FRT. Amnesty claims, with evidence from around the world, that criminal FRS greatly threatens the rights of minority communities and people with darker skin, who are at risk of [~false identification~](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf?ref=static.internetfreedom.in) and [~false arrests~](https://cacmb4.acm.org/news/249620-another-arrest-and-jail-time-due-to-a-bad-facial-recognition-match/fulltext?ref=static.internetfreedom.in). As we have tracked in our surveillance and transparency endeavour, [~Project Panoptic~](https://panoptic.in/?ref=static.internetfreedom.in), the Indian government has spent a whopping 9.6 billion rupees on FRT despite several human rights concerns. \n\nFRT is an extremely invasive and dangerous surveillance tool which poses a direct threat to individual privacy, especially at the hands of law enforcement. Police forces are able to amass and process large volumes of sensitive facial data without any checks, consent, transparency, or procedural safeguards. If too accurate, the deployment of such tech perpetuates the creation of a surveillance regime, where citizens are constantly placed under a watchful eye, and their fundamental rights to free speech, dignity, privacy, and even life, can be infringed upon without checks and balances. If inaccurate, it can lead to the incrimination of innocent persons, as police forces liberally use FRT for criminal identification—often with high error margins. \n\nWe, at IFF, have consistently opposed and condemned the use of FRT by Indian law enforcement agencies. Such flawed and invasive tools infringes upon privacy and civil liberties of not only convicted criminals, but also a large volume of unsuspecting innocent persons, all in the absence of legal safeguards. Facial biometric data is a highly sensitive kind of personal data that can be weaponised to profile, police, and silence citizens. This massive data leak in TN police’s FRT database is proof that the manner in which such sensitive data is being stored is completely unsecured too—we have [~written to CERT-In~](https://drive.google.com/file/d/1t7xhw8BCzu2KKYWg9WYoTeSzJjMAK4rN/view?usp=drive_link&ref=static.internetfreedom.in) urging them to investigate the leak promptly. Given the scale of privacy violation due to this leak, it time to #BanTheScan, especially when it comes to police use of FRT.\n\n# Important documents\n\n1. IFF’s letter to CERT-In on the Tamil Nadu FRT portal data leak dated May 15, 2024 ([~link~](https://drive.google.com/file/d/1t7xhw8BCzu2KKYWg9WYoTeSzJjMAK4rN/view?usp=drive_link&ref=static.internetfreedom.in))\n2. IFF’s post titled ‘Madras HC issues notice on petition challenging use of FRT in Tamil Nadu’ ([~link~](https://internetfreedom.in/tamil-nadu-frt-challenge/?ref=static.internetfreedom.in))\n3. IFF’s post titled ‘From investigation to conviction: How does the Police use FRT?’ ([~link~](https://internetfreedom.in/from-investigation-to-conviction-how-does-the-police-use-frt/?ref=static.internetfreedom.in))\n4. IFF’s Project Panoptic ([~link~](https://panoptic.in/?ref=static.internetfreedom.in))\n5. Amnesty International’s Ban The Scan campaign ([~link~](https://banthescan.amnesty.org/hyderabad/?ref=static.internetfreedom.in))\n\n  \n*Help us watch the watchmen. Become an* [*IFF member*](https://internetfreedom.in/donate/) *today and stand up for your digital rights.*  ",
    "flair": "Law & Courts",
    "score": 100,
    "num_comments": 4,
    "created_utc": 1716368046.0,
    "convurl": "https://b.thumbs.redditmedia.com/_Tmb0vwQlhyjM4QSOQLlcgyKrwQDl1hOITUFtyacjDo.jpg",
    "comments": [
        "This is impressive, well sourced work. Thank you for sharing/doing it.",
        "I sincerely hope this picks up attention in the Indian society. The people who I am still in contact with are very fatalistic about the subject, or hold the “why would someone care about me” or “i have nothing to hide” responses.",
        "Why bother! We have a top court that says privacy is not a right and the public good overrides the privilege of privacy of individuals."
    ],
    "cleaned_text": "massive leak tamil nadu polices facial recognition portal database must herald end police use surveillance technologies banthescan iff needs support ever details end posthttpspreviewredditwbpwopyxdpngwidthformatpngautowebpscbadcccacbbbcbdbcf tldr massive leak tamil nadu polices facial recognition portal revealed many scary truths centrally stored facial biometric data suspects criminals ipso facto violation privacy human rights also securely stored adequately regulated indian law blatant lack checks balances law enforcement uses surveillance tools like frt also makes criminal identification systems breeding grounds discrimination targeted policing disenfranchisement historically marginalised groups post explores recent data leak frt systems work criminal investigations law lack thereof regulate also calls attention significant global campaign banthescan context indian police forces use frt need hour background may threat intelligence platform falconfeedsiohttpfalconfeedsio reportedhttpsxcomfalconfeedsiostatusrefstaticinternetfreedomin massive breach tamil nadu tn polices facial recognition portal exposed lines data including match reports facial recognition system frs categories leaked data includehttpswwwmedianamacomtamilnadupolicefacialrecognitionportaldatabreachexposesoverusersdetailsrefstaticinternetfreedomin police officer data users personally identifiable information including user id user name first name last name police station district contact last login date joined active status staff status superuser status login types verified person types police station data police stations data including police station id police station name code district district code pin code contact details police id data users data including user id image user name first name last name police station name district email address fir data firs fir id nic fir number fir number person category police station district investigating officer launch date occurrence date stage case name fir age gender parentage address alert data searchesalerts made police officers along following data alert id alert query query fir alert fir source police station source district target police station target district alert result matched reason alert made launch date back date initial comment alert state tn police promptly responded press releasehttpspbstwimgcommediagmvdueasaerfgpformatjpgnamelargerefstaticinternetfreedomin day claiming password admin account compromised since deactivated stated last security audit portal carried tamil nadu egovernance agency tnega march preventive measure tn police deactivated admin account claimedhttpswwwnewindianexpresscomstatestamilnadumaytamilnadupolicesfacerecognitionportalhackedfirpersonalinformationupforsalerefstaticinternetfreedomin unauthorised users view front end data like creation id users queries search hence could accessed backend data main server data added complaint filed cyber crime police station chennai key departments notified leak action frs work frs portal software used tn police developedhttpswwwcdacinindexaspxidpkitnspotrefstaticinternetfreedomin centre development advanced computing cdac kolkata division hosted server tamil nadu state data centre electronics corporation tamil nadu tnsdcelcot generated facial recognition reports time police officer ran query image ie picture person identified software helps tn police capture images wanted persons missing persons unidentified corpses central crime criminal tracking network systems cctns databasehttpswwwdigitalpolicecitizenservicesgovinrefstaticinternetfreedomin portal comprising facial biometric data reports used users across tamil nadu interface suffered leak compromised password analysedhttpsinternetfreedominfrominvestigationtoconvictionhowdoesthepoliceusefrtrefstaticinternetfreedomin indian police forces use facial recognition technology frt police forces use two primary purposesverification identification verification authentication done matching live photograph person preexisting photograph uploaded government frt database ensure person presented claiming also called matching ubiquitous among government administrative departments use frt authenticate identity individual seeking gain access benefits government schemes identification hand heavily relied police forces rounding criminals suspects done trying get match face individual usually suspect extracted photographvideo taken police station entire criminal database maintained state police order ascertain identity individual also called many matching usually frs used police produce reports list close matches also called probability match score confidence score suspect identified preexisting frt database tn police many state police systems cctns serves central storage facial data suspect matched read critical analysis cctns storage tracking system surveillance privacy concerns herehttpsstaticinternetfreedominwatchthewatchmenpart every frs match report multiple possible matches generated listed basis likelihood correct match corresponding confidence scores final identification however done police officer selects one match list matches generated technology identification procedure globally critiquedhttphrlrlawcolumbiaeduhrlronlineyoucanseemyfacewhycantifacialrecognitionandbradyrefstaticinternetfreedomin ripe misidentification software releases several possible matches police officer human analyst conducting search makes final identification methodology also opens door police officers biases creep final result wherein may prejudiced certain race religion community based decision making may affected indian police forces deep historyhttpslongreadstniorgstateofpowersettledhabitsnewtrickscasteistpolicingmeetsbigtechinindiarefstaticinternetfreedomin institutionalised biases targeted policing certain minorities many existing police databases reflect biases relying cryptic technologies impossible common men understand make significant law enforcement decisions identifying criminals making arrests legitimise existing biassed data absolve police forces officers accountability even work accuracy rates generated frt depend number factorshttphrlrlawcolumbiaeduhrlronlineyoucanseemyfacewhycantifacialrecognitionandbradyrefstaticinternetfreedomincamera quality light distance database size algorithm suspects race gender name advanced systems around globe achieve accuracy rates still means chances misidentification high enough misidentification false positives occur person identified someone especially concerning lead police pursuing charging innocent persons crime commit existing police databases flawed biassed chances implicating persons belonging certain minorities marginalisations also become high markedly different identification kinds biometric prints like fingerprints dna samples researchhttpswwwnacdlorggetattachmentccfdebdbcfadchallengingfacialrecognitionsoftwareincriminalcourtjulypdfrefstaticinternetfreedomin done national association criminal defense lawyers shows sample contaminated enough biometric data either insufficient dna partial latent fingerprint result inconclusive facial recognition different even matches include correct suspect analyst conducting search selecting match forward investigators may choose wrong individual correct match may even list results identified software analyst reviewing results may find match anyway thereby implicating innocent person false positive found right information rti requests police forces india low accuracy rateshttpsinternetfreedomindelhipolicesfrtuseisaccurateandscaryrefstaticinternetfreedomin deploying frt accuracy frt depends light conditions distance angle face delhi police matches similarity treated positive results matches similarity treated false positive results require additional corroborative evidence unclear astounding chosen threshold match positive match score sufficient assume results correct justification provided classification moreover distinction categorisation results false positive instead negative shows delhi police may still try use results investigation trying methods corroborative evidence means even technology give sufficient enough result police may continue investigate anyone may gotten low match score logic person looks even slightly similar could end targeted raising concerns people historically marginalised communities according submissionhttpswwwbusinessstandardcomarticleptistoriesdelhipolicefacialrecognitionsoftwarehasonlypercentaccuracyhctoldhtmlrefstaticinternetfreedomin made high court delhi accuracy rate frt used delhi police two percent inaccuracy however indian problem solved better technology according reporthttpswwwperpetuallineuporgfindingsaccuracyrefstaticinternetfreedomin georgetown laws center privacy technology fbis statisticshttpswwwtheguardiancomworldoctpolicefacialrecognitiondatabasesurveillanceprofilingrefstaticinternetfreedomin suggest one every seven searches facial recognition database fails turn correct match meaning software occasionally produces potential matches innocent complete information frt systems india respective accuracy rates due lack transparency part government authorities safe assume accuracy rates significantly lower fbishttpswwwgaogovproductsgaotrefstaticinternetfreedomintextadditionalworkremainsfacerecognitiontechnologyadojandfbihavetakensomeactionspublishedajunctextthefbisfacerecognitionofficephotoscincludingstatedatabases accuracy rate unlike delhi tn police access advanced technology world prevented law right right stands today use frt surveillance systems regulated law force india standards guidelines circulars policy documents even internal office memorandum least public domain place regulate technology certify quality accuracy yet police forces increasingly becoming largest deployershttpswwwmedianamacomgrowingusedronespolicerefstaticinternetfreedomin various surveillance tools farfetched think frs deployed subpar quality may easily lead misidentification ultimately false convictions even digital personal data protection act dpdpa comes play procedural rules notified still may able adequately protect sensitive facial biometric data suspects criminals system regulate use police forces two reasons section act holds power exempt government instrumentalities law enforcement agencies application given time highly likely exemption afforded police forces law enforcement often given far wide regulatory exemptions purposes maintaining public order safety security valuable provisions seeking informed verifiable consent data sharing among others apply police use frt dpdpa classify sensitive personal data distinct category needing additional safeguards caution like earlier versions even information technology reasonable security practices procedures sensitive personal data information rules global instruments recognise sensitive nature biometric information facial data vulnerable position processing data may leave data principles european councils guidelines facial recognitionhttpsrmcoeintguidelinesfacialrecognitionwebaarefstaticinternetfreedomin recognise considering potential intrusiveness facial recognition technologies legislators decision makers ensure explicit precise legal basis provides necessary safeguards processing biometric data legal basis include strict necessity proportionality use take consideration vulnerability data subjects nature environment technologies used verification purposes therefore specific rules dpdpa prescribe higher standards processing sensitive information facial biometric data criminal frs across india continue operate without appropriate privacy safeguards pertinent note tn police attempts legitimise use frs drawing powers identify criminals tamil nadu district police act code criminal procedure using wide interpretation policing powers actively progresshttpswwwthenewsminutecomarticlechennaipolicesusefacialrecognitiontechnologycommuterdrawsflakrefstaticinternetfreedomin towards installing deploying frt systems across state instance april government equipped personnel field police stations frts since government installed facial recognitionenabled cctv cameras crimesensitive locations commenced operating technology kancheepuram madurai march however constitutional validity tn polices legal interpretation use frt ubiquitous legal challengehttpsinternetfreedomintamilnadufrtchallengerefstaticinternetfreedomin petitioner assisted iff challenged deployment grounds supreme court ks puttaswamy v union india orshttpsindiankanoonorgdocrefstaticinternetfreedomin scc held government curtail right privacy unless restriction grounded law necessary proportionate manner implementation frt infringes right privacy fails fivepronged proportionality test laid supreme court b lacks legislative authorisation thus fails test legality reliance placed tamil nadu district police act code criminal procedure inherently flawed c even held frt sufficiently grounded within existing legislation still fails prongs proportionality requirement specifically rationality necessity balancing safeguards abuse deployment frt demonstrably discriminatory nature hence without prior impact assessment violates article constitution await next date hearing matter time banthescan know frt used police forces accurate know lead rights violations disenfranchisement historically marginalised groups know deployed without legal safeguards checks balances massive leak tn frs portal know facial data collected vast numbers also secure given privacy human rights violations surveillance concerns associated criminal frs far outweigh benefits time police forces stop using altogether similar demand echoed amnesty internationals ban scanhttpsbanthescanamnestyorghyderabadrefstaticinternetfreedomin campaign call completely withdraw private public use frs owing high risks associated frt amnesty claims evidence around world criminal frs greatly threatens rights minority communities people darker skin risk false identificationhttpsproceedingsmlrpressvbuolamwiniabuolamwiniapdfrefstaticinternetfreedomin false arrestshttpscacmbacmorgnewsanotherarrestandjailtimeduetoabadfacialrecognitionmatchfulltextrefstaticinternetfreedomin tracked surveillance transparency endeavour project panoptichttpspanopticinrefstaticinternetfreedomin indian government spent whopping billion rupees frt despite several human rights concerns frt extremely invasive dangerous surveillance tool poses direct threat individual privacy especially hands law enforcement police forces able amass process large volumes sensitive facial data without checks consent transparency procedural safeguards accurate deployment tech perpetuates creation surveillance regime citizens constantly placed watchful eye fundamental rights free speech dignity privacy even life infringed upon without checks balances inaccurate lead incrimination innocent persons police forces liberally use frt criminal identificationoften high error margins iff consistently opposed condemned use frt indian law enforcement agencies flawed invasive tools infringes upon privacy civil liberties convicted criminals also large volume unsuspecting innocent persons absence legal safeguards facial biometric data highly sensitive kind personal data weaponised profile police silence citizens massive data leak tn polices frt database proof manner sensitive data stored completely unsecured toowe written certinhttpsdrivegooglecomfiledtxhwbczukkywgwyoteszjjmakrnviewuspdrivelinkrefstaticinternetfreedomin urging investigate leak promptly given scale privacy violation due leak time banthescan especially comes police use frt important documents iffs letter certin tamil nadu frt portal data leak dated may linkhttpsdrivegooglecomfiledtxhwbczukkywgwyoteszjjmakrnviewuspdrivelinkrefstaticinternetfreedomin iffs post titled madras hc issues notice petition challenging use frt tamil nadu linkhttpsinternetfreedomintamilnadufrtchallengerefstaticinternetfreedomin iffs post titled investigation conviction police use frt linkhttpsinternetfreedominfrominvestigationtoconvictionhowdoesthepoliceusefrtrefstaticinternetfreedomin iffs project panoptic linkhttpspanopticinrefstaticinternetfreedomin amnesty internationals ban scan campaign linkhttpsbanthescanamnestyorghyderabadrefstaticinternetfreedomin help us watch watchmen become iff memberhttpsinternetfreedomindonate today stand digital rights ",
    "cleaned_title": "massive leak tamil nadu polices facial recognition portal database must herald end police use surveillance technologies banthescan",
    "cleaned_selftext": "iff needs support ever details end posthttpspreviewredditwbpwopyxdpngwidthformatpngautowebpscbadcccacbbbcbdbcf tldr massive leak tamil nadu polices facial recognition portal revealed many scary truths centrally stored facial biometric data suspects criminals ipso facto violation privacy human rights also securely stored adequately regulated indian law blatant lack checks balances law enforcement uses surveillance tools like frt also makes criminal identification systems breeding grounds discrimination targeted policing disenfranchisement historically marginalised groups post explores recent data leak frt systems work criminal investigations law lack thereof regulate also calls attention significant global campaign banthescan context indian police forces use frt need hour background may threat intelligence platform falconfeedsiohttpfalconfeedsio reportedhttpsxcomfalconfeedsiostatusrefstaticinternetfreedomin massive breach tamil nadu tn polices facial recognition portal exposed lines data including match reports facial recognition system frs categories leaked data includehttpswwwmedianamacomtamilnadupolicefacialrecognitionportaldatabreachexposesoverusersdetailsrefstaticinternetfreedomin police officer data users personally identifiable information including user id user name first name last name police station district contact last login date joined active status staff status superuser status login types verified person types police station data police stations data including police station id police station name code district district code pin code contact details police id data users data including user id image user name first name last name police station name district email address fir data firs fir id nic fir number fir number person category police station district investigating officer launch date occurrence date stage case name fir age gender parentage address alert data searchesalerts made police officers along following data alert id alert query query fir alert fir source police station source district target police station target district alert result matched reason alert made launch date back date initial comment alert state tn police promptly responded press releasehttpspbstwimgcommediagmvdueasaerfgpformatjpgnamelargerefstaticinternetfreedomin day claiming password admin account compromised since deactivated stated last security audit portal carried tamil nadu egovernance agency tnega march preventive measure tn police deactivated admin account claimedhttpswwwnewindianexpresscomstatestamilnadumaytamilnadupolicesfacerecognitionportalhackedfirpersonalinformationupforsalerefstaticinternetfreedomin unauthorised users view front end data like creation id users queries search hence could accessed backend data main server data added complaint filed cyber crime police station chennai key departments notified leak action frs work frs portal software used tn police developedhttpswwwcdacinindexaspxidpkitnspotrefstaticinternetfreedomin centre development advanced computing cdac kolkata division hosted server tamil nadu state data centre electronics corporation tamil nadu tnsdcelcot generated facial recognition reports time police officer ran query image ie picture person identified software helps tn police capture images wanted persons missing persons unidentified corpses central crime criminal tracking network systems cctns databasehttpswwwdigitalpolicecitizenservicesgovinrefstaticinternetfreedomin portal comprising facial biometric data reports used users across tamil nadu interface suffered leak compromised password analysedhttpsinternetfreedominfrominvestigationtoconvictionhowdoesthepoliceusefrtrefstaticinternetfreedomin indian police forces use facial recognition technology frt police forces use two primary purposesverification identification verification authentication done matching live photograph person preexisting photograph uploaded government frt database ensure person presented claiming also called matching ubiquitous among government administrative departments use frt authenticate identity individual seeking gain access benefits government schemes identification hand heavily relied police forces rounding criminals suspects done trying get match face individual usually suspect extracted photographvideo taken police station entire criminal database maintained state police order ascertain identity individual also called many matching usually frs used police produce reports list close matches also called probability match score confidence score suspect identified preexisting frt database tn police many state police systems cctns serves central storage facial data suspect matched read critical analysis cctns storage tracking system surveillance privacy concerns herehttpsstaticinternetfreedominwatchthewatchmenpart every frs match report multiple possible matches generated listed basis likelihood correct match corresponding confidence scores final identification however done police officer selects one match list matches generated technology identification procedure globally critiquedhttphrlrlawcolumbiaeduhrlronlineyoucanseemyfacewhycantifacialrecognitionandbradyrefstaticinternetfreedomin ripe misidentification software releases several possible matches police officer human analyst conducting search makes final identification methodology also opens door police officers biases creep final result wherein may prejudiced certain race religion community based decision making may affected indian police forces deep historyhttpslongreadstniorgstateofpowersettledhabitsnewtrickscasteistpolicingmeetsbigtechinindiarefstaticinternetfreedomin institutionalised biases targeted policing certain minorities many existing police databases reflect biases relying cryptic technologies impossible common men understand make significant law enforcement decisions identifying criminals making arrests legitimise existing biassed data absolve police forces officers accountability even work accuracy rates generated frt depend number factorshttphrlrlawcolumbiaeduhrlronlineyoucanseemyfacewhycantifacialrecognitionandbradyrefstaticinternetfreedomincamera quality light distance database size algorithm suspects race gender name advanced systems around globe achieve accuracy rates still means chances misidentification high enough misidentification false positives occur person identified someone especially concerning lead police pursuing charging innocent persons crime commit existing police databases flawed biassed chances implicating persons belonging certain minorities marginalisations also become high markedly different identification kinds biometric prints like fingerprints dna samples researchhttpswwwnacdlorggetattachmentccfdebdbcfadchallengingfacialrecognitionsoftwareincriminalcourtjulypdfrefstaticinternetfreedomin done national association criminal defense lawyers shows sample contaminated enough biometric data either insufficient dna partial latent fingerprint result inconclusive facial recognition different even matches include correct suspect analyst conducting search selecting match forward investigators may choose wrong individual correct match may even list results identified software analyst reviewing results may find match anyway thereby implicating innocent person false positive found right information rti requests police forces india low accuracy rateshttpsinternetfreedomindelhipolicesfrtuseisaccurateandscaryrefstaticinternetfreedomin deploying frt accuracy frt depends light conditions distance angle face delhi police matches similarity treated positive results matches similarity treated false positive results require additional corroborative evidence unclear astounding chosen threshold match positive match score sufficient assume results correct justification provided classification moreover distinction categorisation results false positive instead negative shows delhi police may still try use results investigation trying methods corroborative evidence means even technology give sufficient enough result police may continue investigate anyone may gotten low match score logic person looks even slightly similar could end targeted raising concerns people historically marginalised communities according submissionhttpswwwbusinessstandardcomarticleptistoriesdelhipolicefacialrecognitionsoftwarehasonlypercentaccuracyhctoldhtmlrefstaticinternetfreedomin made high court delhi accuracy rate frt used delhi police two percent inaccuracy however indian problem solved better technology according reporthttpswwwperpetuallineuporgfindingsaccuracyrefstaticinternetfreedomin georgetown laws center privacy technology fbis statisticshttpswwwtheguardiancomworldoctpolicefacialrecognitiondatabasesurveillanceprofilingrefstaticinternetfreedomin suggest one every seven searches facial recognition database fails turn correct match meaning software occasionally produces potential matches innocent complete information frt systems india respective accuracy rates due lack transparency part government authorities safe assume accuracy rates significantly lower fbishttpswwwgaogovproductsgaotrefstaticinternetfreedomintextadditionalworkremainsfacerecognitiontechnologyadojandfbihavetakensomeactionspublishedajunctextthefbisfacerecognitionofficephotoscincludingstatedatabases accuracy rate unlike delhi tn police access advanced technology world prevented law right right stands today use frt surveillance systems regulated law force india standards guidelines circulars policy documents even internal office memorandum least public domain place regulate technology certify quality accuracy yet police forces increasingly becoming largest deployershttpswwwmedianamacomgrowingusedronespolicerefstaticinternetfreedomin various surveillance tools farfetched think frs deployed subpar quality may easily lead misidentification ultimately false convictions even digital personal data protection act dpdpa comes play procedural rules notified still may able adequately protect sensitive facial biometric data suspects criminals system regulate use police forces two reasons section act holds power exempt government instrumentalities law enforcement agencies application given time highly likely exemption afforded police forces law enforcement often given far wide regulatory exemptions purposes maintaining public order safety security valuable provisions seeking informed verifiable consent data sharing among others apply police use frt dpdpa classify sensitive personal data distinct category needing additional safeguards caution like earlier versions even information technology reasonable security practices procedures sensitive personal data information rules global instruments recognise sensitive nature biometric information facial data vulnerable position processing data may leave data principles european councils guidelines facial recognitionhttpsrmcoeintguidelinesfacialrecognitionwebaarefstaticinternetfreedomin recognise considering potential intrusiveness facial recognition technologies legislators decision makers ensure explicit precise legal basis provides necessary safeguards processing biometric data legal basis include strict necessity proportionality use take consideration vulnerability data subjects nature environment technologies used verification purposes therefore specific rules dpdpa prescribe higher standards processing sensitive information facial biometric data criminal frs across india continue operate without appropriate privacy safeguards pertinent note tn police attempts legitimise use frs drawing powers identify criminals tamil nadu district police act code criminal procedure using wide interpretation policing powers actively progresshttpswwwthenewsminutecomarticlechennaipolicesusefacialrecognitiontechnologycommuterdrawsflakrefstaticinternetfreedomin towards installing deploying frt systems across state instance april government equipped personnel field police stations frts since government installed facial recognitionenabled cctv cameras crimesensitive locations commenced operating technology kancheepuram madurai march however constitutional validity tn polices legal interpretation use frt ubiquitous legal challengehttpsinternetfreedomintamilnadufrtchallengerefstaticinternetfreedomin petitioner assisted iff challenged deployment grounds supreme court ks puttaswamy v union india orshttpsindiankanoonorgdocrefstaticinternetfreedomin scc held government curtail right privacy unless restriction grounded law necessary proportionate manner implementation frt infringes right privacy fails fivepronged proportionality test laid supreme court b lacks legislative authorisation thus fails test legality reliance placed tamil nadu district police act code criminal procedure inherently flawed c even held frt sufficiently grounded within existing legislation still fails prongs proportionality requirement specifically rationality necessity balancing safeguards abuse deployment frt demonstrably discriminatory nature hence without prior impact assessment violates article constitution await next date hearing matter time banthescan know frt used police forces accurate know lead rights violations disenfranchisement historically marginalised groups know deployed without legal safeguards checks balances massive leak tn frs portal know facial data collected vast numbers also secure given privacy human rights violations surveillance concerns associated criminal frs far outweigh benefits time police forces stop using altogether similar demand echoed amnesty internationals ban scanhttpsbanthescanamnestyorghyderabadrefstaticinternetfreedomin campaign call completely withdraw private public use frs owing high risks associated frt amnesty claims evidence around world criminal frs greatly threatens rights minority communities people darker skin risk false identificationhttpsproceedingsmlrpressvbuolamwiniabuolamwiniapdfrefstaticinternetfreedomin false arrestshttpscacmbacmorgnewsanotherarrestandjailtimeduetoabadfacialrecognitionmatchfulltextrefstaticinternetfreedomin tracked surveillance transparency endeavour project panoptichttpspanopticinrefstaticinternetfreedomin indian government spent whopping billion rupees frt despite several human rights concerns frt extremely invasive dangerous surveillance tool poses direct threat individual privacy especially hands law enforcement police forces able amass process large volumes sensitive facial data without checks consent transparency procedural safeguards accurate deployment tech perpetuates creation surveillance regime citizens constantly placed watchful eye fundamental rights free speech dignity privacy even life infringed upon without checks balances inaccurate lead incrimination innocent persons police forces liberally use frt criminal identificationoften high error margins iff consistently opposed condemned use frt indian law enforcement agencies flawed invasive tools infringes upon privacy civil liberties convicted criminals also large volume unsuspecting innocent persons absence legal safeguards facial biometric data highly sensitive kind personal data weaponised profile police silence citizens massive data leak tn polices frt database proof manner sensitive data stored completely unsecured toowe written certinhttpsdrivegooglecomfiledtxhwbczukkywgwyoteszjjmakrnviewuspdrivelinkrefstaticinternetfreedomin urging investigate leak promptly given scale privacy violation due leak time banthescan especially comes police use frt important documents iffs letter certin tamil nadu frt portal data leak dated may linkhttpsdrivegooglecomfiledtxhwbczukkywgwyoteszjjmakrnviewuspdrivelinkrefstaticinternetfreedomin iffs post titled madras hc issues notice petition challenging use frt tamil nadu linkhttpsinternetfreedomintamilnadufrtchallengerefstaticinternetfreedomin iffs post titled investigation conviction police use frt linkhttpsinternetfreedominfrominvestigationtoconvictionhowdoesthepoliceusefrtrefstaticinternetfreedomin iffs project panoptic linkhttpspanopticinrefstaticinternetfreedomin amnesty internationals ban scan campaign linkhttpsbanthescanamnestyorghyderabadrefstaticinternetfreedomin help us watch watchmen become iff memberhttpsinternetfreedomindonate today stand digital rights",
    "cleaned_comments": "impressive well sourced work thank sharingdoing sincerely hope picks attention indian society people still contact fatalistic subject hold would someone care nothing hide responses bother top court says privacy right public good overrides privilege privacy individuals",
    "light_cleaned_title": "Why a massive leak in Tamil Nadu Police’s Facial Recognition Portal database must herald the end of police use of surveillance technologies | #BanTheScan",
    "light_cleaned_selftext": "[IFF needs your support, now more than ever. Details at the end of this post.](https://preview.redd.it/8wb4pwopyx1d1.png?width=1600&format=png&auto=webp&s=c37b22ad8c1c3099c2acbb936b8cb8139dbc88f3) # tl;dr A massive leak in the Tamil Nadu police’s Facial Recognition Portal has revealed many scary truths. Not only is centrally stored facial biometric data of suspects and criminals an *ipso facto* violation of their privacy and human rights, but it is also not securely stored or adequately regulated under Indian law. The blatant lack of checks and balances on how law enforcement uses surveillance tools like FRT also makes such criminal identification systems breeding grounds for discrimination, targeted policing, and disenfranchisement of historically marginalised groups. This post explores the recent data leak, how FRT systems work in criminal investigations, and the law (or lack thereof) to regulate it; and also calls attention to a significant global campaign #BanTheScan, which in context of how Indian police forces use FRT, is the need of the hour. # Background On May 4, 2024, threat intelligence platform [FalconFeeds.io](http://FalconFeeds.io) [~reported~](https://x.com/FalconFeedsio/status/1786614640908304764?ref=static.internetfreedom.in) a massive breach in Tamil Nadu (“**TN**”) Police’s Facial Recognition Portal, which exposed over 8,00,000 lines of data, including match reports from their Facial Recognition System (“**FRS**”). Other categories of leaked data [~include~](https://www.medianama.com/2024/05/223-tamil-nadu-police-facial-recognition-portal-data-breach-exposes-over-50000-users-details/?ref=static.internetfreedom.in): * **Police officer Data:** 54,828 users’ personally identifiable information, including user ID, user name, first name, last name, police station, district, contact, last login, date joined, active status, staff status, superuser status, login type(s), verified person type(s); * **Police Station Data:** 2,738 police stations’ data, including the police station ID, police station name, code, district, district code, pin code, contact details; * **Police ID data:** 54,934 users’ data, including user ID, image, user name, first name, last name, police station name, district, email address; * **FIR Data:** 8,98,352 FIRs with FIR ID, NIC FIR number, FIR number, person category, police station, district, investigating officer, launch date, occurrence date, stage of the case, name in FIR, age, gender, parentage, address; * **Alert Data:** 235,753 Searches/Alerts made by police officers, along with the following data: Alert ID, alert against the query, query fir, alert against fir, source police station, source district, target police station, target district, alert result, not matched reason, alert made by, launch date, back date, initial comment, alert state. The TN police promptly responded through a [~press release~](https://pbs.twimg.com/media/GMvD9UEasAERfGP?format=jpg&name=large&ref=static.internetfreedom.in) the same day, claiming that the password of an admin account was compromised and has since been deactivated. They stated that the last security audit of the portal was carried out by Tamil Nadu e-Governance Agency (“**TNeGA**”) on March 13, 2024. As a preventive measure, the TN police have deactivated the admin account. They [~claimed~](https://www.newindianexpress.com/states/tamil-nadu/2024/May/05/tamil-nadu-polices-face-recognition-portal-hacked-fir-personal-information-up-for-sale?ref=static.internetfreedom.in) that unauthorised users can view only the front end data (like creation of ID for users, queries search) and hence could not have accessed the backend data or main server data. They added that a complaint has been filed at the Cyber Crime Police Station, Chennai and key departments have been notified of the leak for further action. # How does the FRS work? The FRS portal and software used by the TN Police was [~developed~](https://www.cdac.in/index.aspx?id=pk_itn_spot1274&ref=static.internetfreedom.in) by the Centre for Development of Advanced Computing (“**CDAC**”), Kolkata division, and hosted on the server at Tamil Nadu State Data Centre, Electronics Corporation of Tamil Nadu (“**TNSDC-ELCOT**”). It generated Facial Recognition Reports each time a police officer ran a query image (i.e. picture of the person to be identified). The software helps the TN Police to capture the images of wanted persons, missing persons, and unidentified corpses from the central Crime and Criminal Tracking Network and Systems (“**CCTNS**”) [~database~](https://www.digitalpolicecitizenservices.gov.in/?ref=static.internetfreedom.in). The portal, comprising all the facial biometric data and reports, is used by 46,112 users across Tamil Nadu. This is the interface that suffered a leak through a compromised password. In 2021, we [~analysed~](https://internetfreedom.in/from-investigation-to-conviction-how-does-the-police-use-frt/?ref=static.internetfreedom.in) how Indian police forces use facial recognition technology (“**FRT**”). Police forces use it for two primary purposes—verification and identification. Verification, or authentication, is done by matching the live photograph of a person to the pre-existing photograph that has been uploaded on any government FRT database. This is to ensure that the person presented is who they are claiming to be, and is also called 1:1 matching. This is more ubiquitous among government administrative departments, which use FRT to authenticate the identity of an individual seeking to gain access to any benefits or government schemes. Identification, on the other hand, is heavily relied on by police forces for rounding up criminals and suspects. This is done by trying to get a match between the face of an individual (usually a suspect) which has been extracted from a photograph/video or taken at the police station, with the entire criminal database maintained by the state police, in order to ascertain the identity of the individual. This is also called 1:many matching. Usually, the FRS used by the police will produce reports with a list of close matches (also called a probability match score or a confidence score) between the suspect who is to be identified and the pre-existing FRT database. For the TN police, as for many other state police systems, the CCTNS serves as a central storage of all such facial data that the suspect can be matched against. Read our critical analysis of the CCTNS storage and tracking system and its surveillance and privacy concerns [~here~](https://static.internetfreedom.in/watch-the-watchmen-part-3/). In every such FRS match report, multiple possible matches are generated and listed on the basis of their likelihood to be the correct match with corresponding confidence scores. The final identification, however, is done by the police officer, who selects one match from the list of matches generated by the technology. This identification procedure has been [~globally critiqued~](http://hrlr.law.columbia.edu/hrlr-online/you-can-see-my-face-why-cant-i-facial-recognition-and-brady/?ref=static.internetfreedom.in) to be ripe for misidentification because, while the software releases several possible matches, the police officer or ‘human analyst’ conducting the search makes the final identification. Such a methodology also opens the door for the police officers’ own biases to creep into the final result wherein they may be prejudiced against a certain race, religion, or community, based on which their decision making may be affected. Indian police forces have a [~deep history~](https://longreads.tni.org/stateofpower/settled-habits-new-tricks-casteist-policing-meets-big-tech-in-india?ref=static.internetfreedom.in) of institutionalised biases and targeted policing against certain minorities, and many existing police databases reflect these biases. Relying on these cryptic technologies (that are impossible for most common men to understand) to make significant law enforcement decisions such as identifying criminals and making arrests, can legitimise the existing biassed data and absolve police forces and officers of any accountability. # But does it even work? The accuracy rates generated by the FRT depend on a [~number of factors~](http://hrlr.law.columbia.edu/hrlr-online/you-can-see-my-face-why-cant-i-facial-recognition-and-brady/?ref=static.internetfreedom.in)—camera quality, light, distance, database size, algorithm, and the suspect’s race and gender, to name a few. Advanced systems around the globe can achieve accuracy rates of 90%, but that still means that chances of misidentification are 10%, which is high enough. Misidentification, or false positives, occur when a person is identified as someone they are not. This is especially concerning as it can lead to the police pursuing and charging innocent persons for a crime they did not commit. And as existing police databases are flawed and biassed, the chances of implicating persons belonging to certain minorities or marginalisations also become high. This is markedly different from identification through other kinds of biometric prints like fingerprints or DNA samples. As [~research~](https://www.nacdl.org/getattachment/548c697c-fd8e-4b8d-b4c3-2540336fad94/challenging-facial-recognition-software-in-criminal-court_july-2019.pdf?ref=static.internetfreedom.in) done at National Association of Criminal Defense Lawyers shows, “*(i)f the sample is contaminated or does not have enough of the biometric data, either insufficient DNA or a partial latent fingerprint, the result is inconclusive. Facial recognition is different; even if the matches include the correct suspect, the analyst conducting the search and selecting the match to forward to investigators may choose the wrong individual. The correct match may not even be in the list of results identified by the software, but the analyst reviewing the results may find a match anyway, thereby implicating an innocent person (a false positive)*.” Further, we have found through Right to Information (“**RTI**”) requests that police forces in India have [~low accuracy rates~](https://internetfreedom.in/delhi-polices-frt-use-is-80-accurate-and-100-scary/?ref=static.internetfreedom.in) while deploying FRT. The accuracy of their FRT depends on light conditions, distance, and angle of face. For the Delhi police, all matches above 80% similarity are treated as positive results while matches below 80% similarity are treated as false positive results which require additional “corroborative evidence”. It is unclear (and astounding) why 80% is chosen as the threshold above which a match will be “positive” and that an above 80% match score is sufficient to assume the results are correct and no justification has been provided for this classification. Moreover, the distinction between categorisation of below 80% results as false positive instead of negative shows that the Delhi police may still try to use below 80% results for further investigation by trying other methods of “corroborative evidence”. This means that, even if the technology does not give a sufficient enough result, the police may continue to investigate anyone who may have gotten a very low match score. By this logic, any person who looks even slightly similar could end up being targeted, raising concerns for people from historically marginalised communities. Further, according to a [~submission~](https://www.business-standard.com/article/pti-stories/delhi-police-facial-recognition-software-has-only-2-per-cent-accuracy-hc-told-118082301289_1.html?ref=static.internetfreedom.in) made before the High Court of Delhi, the accuracy rate of the FRT being used by the Delhi Police is 2%. TWO PERCENT!!! Inaccuracy, however, is not an Indian problem which can be solved with “better” technology. According to a [~report~](https://www.perpetuallineup.org/findings/accuracy?ref=static.internetfreedom.in) by Georgetown Law’s Center on Privacy and Technology, the FBI’s [~own statistics~](https://www.theguardian.com/world/2016/oct/18/police-facial-recognition-database-surveillance-profiling?ref=static.internetfreedom.in) suggest that one out of every seven searches of its facial recognition database fails to turn up a correct match, meaning the software occasionally produces 50 “potential” matches who are all “innocent”. While we do not have any complete information about all FRT systems in India and their respective accuracy rates due to a lack of transparency on the part of the government authorities, it is safe to assume that their accuracy rates will be significantly lower than the [~FBI’s~](https://www.gao.gov/products/gao-19-579t?ref=static.internetfreedom.in#:~:text=Additional%20Work%20Remains-,Face%20Recognition%20Technology%3A%20DOJ%20and%20FBI%20Have%20Taken%20Some%20Actions,Published%3A%20Jun%2004%2C%202019.&text=The%20FBI's%20face%20recognition%20office,photos%2C%20including%2021%20state%20databases) 86% accuracy rate… which, unlike Delhi or TN police, has access to the most advanced technology in the world. # But all this can be prevented by the law right? Right??? As it stands today, use of FRT or any surveillance systems is not regulated by any law in force in India. There are no standards, guidelines, circulars, policy documents, or even internal office memorandum (at least in the public domain) in place to regulate the technology or certify its quality or accuracy. Yet, police forces are increasingly becoming the [~largest deployers~](https://www.medianama.com/2023/04/223-growing-use-drones-police/?ref=static.internetfreedom.in) of various surveillance tools. It is not far-fetched to think that the FRS being deployed by them is sub-par in quality and may easily lead to misidentification, and ultimately, false convictions. Even when the Digital Personal Data Protection Act, 2023 (“**DPDPA**”) comes into play with its procedural Rules notified, it still may not be able to adequately protect the sensitive facial biometric data of suspects or criminals in the system, or regulate its use by police forces. This is for two reasons. 1. Section 17 of the Act holds the power to exempt government instrumentalities and law enforcement agencies from its very application at any given time. It is highly likely that such an exemption will be afforded to police forces, as law enforcement is often given far and wide regulatory exemptions for purposes of maintaining public order, safety, or security. The valuable provisions of seeking informed and verifiable consent before data sharing, among others, will not apply to police use of FRT. 2. The DPDPA does not classify ‘sensitive personal data’ as a distinct category needing additional safeguards and caution, like its earlier versions or even the Information Technology (*Reasonable Security Practices and Procedures and Sensitive Personal Data or Information*) Rules, 2011. Global instruments recognise the sensitive nature of biometric information such as facial data and the vulnerable position the processing of such data may leave the data principles in. As the European Council’s ‘[~Guidelines on facial recognition~](https://rm.coe.int/guidelines-facial-recognition-web-a5-2750-3427-6868-1/1680a31751?ref=static.internetfreedom.in)’ recognise, >“*Considering the potential intrusiveness of these \\[facial recognition\\] technologies, legislators and decision makers have to ensure that an explicit and precise legal basis provides the necessary safeguards for the processing of biometric data. Such a legal basis will include the strict necessity and proportionality of their use and will take into consideration the vulnerability of the data subjects and the nature of the environment in which these technologies are used for verification purposes.*” Therefore, until specific Rules under the DPDPA prescribe higher standards for processing sensitive information such as facial biometric data, criminal FRS across India will continue to operate without appropriate privacy safeguards. It is pertinent to note that the TN police attempts to legitimise their use of FRS by drawing powers to identify criminals under the Tamil Nadu District Police Act, 1859 and the Code of Criminal Procedure, 1973. They have been using this wide interpretation of policing powers to [~actively progress~](https://www.thenewsminute.com/article/chennai-police-s-use-facial-recognition-technology-commuter-draws-flak-170753?ref=static.internetfreedom.in) towards installing and deploying FRT systems across the state. For instance, by April 2022, the government had equipped over 40,000 personnel in the field and police stations with FRTs, and since 2018, the government has installed facial recognition-enabled CCTV cameras in 100 “crime-sensitive” locations and had commenced operating the technology in Kancheepuram and Madurai as of March 2022. However, the constitutional validity of TN police’s legal interpretation and use of FRT ubiquitous is under [~legal challenge~](https://internetfreedom.in/tamil-nadu-frt-challenge/?ref=static.internetfreedom.in), where the petitioner is assisted by IFF. We have challenged the deployment on the grounds that a) the Supreme Court in [*~K.S. Puttaswamy v. Union of India & Ors~*](https://indiankanoon.org/doc/91938676/?ref=static.internetfreedom.in) *(2017) 10 SCC 1* has held that the government cannot curtail the right to privacy unless such restriction is grounded in law, and is necessary and proportionate; and the manner of implementation of the FRT infringes the right to privacy, as it fails the five-pronged proportionality test laid by the Supreme Court; b) it lacks legislative authorisation and thus, fails the test of legality, as the reliance placed on Tamil Nadu District Police Act of 1859 and Code of Criminal Procedure of 1973 is inherently flawed; c) even if it is held that the FRT is sufficiently grounded within existing legislation, it still fails the other prongs of proportionality requirement, specifically, rationality, necessity, balancing and safeguards against abuse; and d) the deployment of FRT is demonstrably discriminatory in nature, and hence, without prior impact assessment, it violates Article 14 of the Constitution. We await the next date of hearing in the matter. # It is time to #BanTheScan We know that FRT used by police forces is not accurate. We know that it can lead to rights violations and disenfranchisement of historically marginalised groups. We know that it is deployed without legal safeguards or checks and balances. After the massive leak in the TN FRS portal, we now know that this facial data collected in vast numbers, is also not secure. Given that the privacy and human rights violations and surveillance concerns associated with criminal FRS far outweigh its benefits, it is time that police forces stop using it altogether. A similar demand is echoed in Amnesty International’s [~Ban The Scan~](https://banthescan.amnesty.org/hyderabad/?ref=static.internetfreedom.in) campaign, which is a call to completely withdraw all private and public use of FRS owing to the high risks associated with FRT. Amnesty claims, with evidence from around the world, that criminal FRS greatly threatens the rights of minority communities and people with darker skin, who are at risk of [~false identification~](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf?ref=static.internetfreedom.in) and [~false arrests~](https://cacmb4.acm.org/news/249620-another-arrest-and-jail-time-due-to-a-bad-facial-recognition-match/fulltext?ref=static.internetfreedom.in). As we have tracked in our surveillance and transparency endeavour, [~Project Panoptic~](https://panoptic.in/?ref=static.internetfreedom.in), the Indian government has spent a whopping 9.6 billion rupees on FRT despite several human rights concerns. FRT is an extremely invasive and dangerous surveillance tool which poses a direct threat to individual privacy, especially at the hands of law enforcement. Police forces are able to amass and process large volumes of sensitive facial data without any checks, consent, transparency, or procedural safeguards. If too accurate, the deployment of such tech perpetuates the creation of a surveillance regime, where citizens are constantly placed under a watchful eye, and their fundamental rights to free speech, dignity, privacy, and even life, can be infringed upon without checks and balances. If inaccurate, it can lead to the incrimination of innocent persons, as police forces liberally use FRT for criminal identification—often with high error margins. We, at IFF, have consistently opposed and condemned the use of FRT by Indian law enforcement agencies. Such flawed and invasive tools infringes upon privacy and civil liberties of not only convicted criminals, but also a large volume of unsuspecting innocent persons, all in the absence of legal safeguards. Facial biometric data is a highly sensitive kind of personal data that can be weaponised to profile, police, and silence citizens. This massive data leak in TN police’s FRT database is proof that the manner in which such sensitive data is being stored is completely unsecured too—we have [~written to CERT-In~](https://drive.google.com/file/d/1t7xhw8BCzu2KKYWg9WYoTeSzJjMAK4rN/view?usp=drive_link&ref=static.internetfreedom.in) urging them to investigate the leak promptly. Given the scale of privacy violation due to this leak, it time to #BanTheScan, especially when it comes to police use of FRT. # Important documents 1. IFF’s letter to CERT-In on the Tamil Nadu FRT portal data leak dated May 15, 2024 ([~link~](https://drive.google.com/file/d/1t7xhw8BCzu2KKYWg9WYoTeSzJjMAK4rN/view?usp=drive_link&ref=static.internetfreedom.in)) 2. IFF’s post titled ‘Madras HC issues notice on petition challenging use of FRT in Tamil Nadu’ ([~link~](https://internetfreedom.in/tamil-nadu-frt-challenge/?ref=static.internetfreedom.in)) 3. IFF’s post titled ‘From investigation to conviction: How does the Police use FRT?’ ([~link~](https://internetfreedom.in/from-investigation-to-conviction-how-does-the-police-use-frt/?ref=static.internetfreedom.in)) 4. IFF’s Project Panoptic ([~link~](https://panoptic.in/?ref=static.internetfreedom.in)) 5. Amnesty International’s Ban The Scan campaign ([~link~](https://banthescan.amnesty.org/hyderabad/?ref=static.internetfreedom.in)) *Help us watch the watchmen. Become an* [*IFF member*](https://internetfreedom.in/donate/) *today and stand up for your digital rights.*",
    "light_cleaned_comments": "This is impressive, well sourced work. Thank you for sharing/doing it. I sincerely hope this picks up attention in the Indian society. The people who I am still in contact with are very fatalistic about the subject, or hold the “why would someone care about me” or “i have nothing to hide” responses. Why bother! We have a top court that says privacy is not a right and the public good overrides the privilege of privacy of individuals."
}